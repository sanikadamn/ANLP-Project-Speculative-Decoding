{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"/scratch/sarthak\"):\n",
    "    os.makedirs(\"/scratch/sarthak\")\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/scratch/sarthak/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EdqllqRvz8YX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoModelForSeq2SeqLM\n",
    "from typing import List, Tuple, Optional\n",
    "import time\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WMT16 EN-DE dataset\n",
    "# def preprocess_function_ende(examples, tokenizer, args, train_args, prefix=\"translate English to German: \"):\n",
    "#     if train_args.debug:\n",
    "#         all_text = examples['translation'][:2]\n",
    "#     else:\n",
    "#         all_text = examples['translation']\n",
    "        \n",
    "#     inputs = []\n",
    "#     targets = []\n",
    "#     for excerpt in all_text:\n",
    "#         en_text = prefix + excerpt['en']\n",
    "#         de_text = excerpt['de']\n",
    "\n",
    "#         inputs.append(en_text)\n",
    "#         targets.append(de_text)\n",
    "            \n",
    "#     padding = 'max_length'\n",
    "#     model_inputs = tokenizer(\n",
    "#         inputs,\n",
    "#         max_length=args.source_max_length,\n",
    "#         padding=padding,\n",
    "#         truncation=True,\n",
    "#         return_tensors=\"pt\",\n",
    "#     )\n",
    "#     # Tokenize targets with the `text_target` keyword argument\n",
    "#     labels = tokenizer(\n",
    "#         text_target=targets,\n",
    "#         max_length=args.train_target_max_length,\n",
    "#         padding=padding,\n",
    "#         truncation=True,\n",
    "    #     return_tensors=\"pt\",\n",
    "    # )\n",
    "\n",
    "    # if padding == \"max_length\":\n",
    "    #             labels[\"input_ids\"] = [\n",
    "    #                 [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    #             ]\n",
    "\n",
    "    # model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    # model_inputs[\"decoder_attention_mask\"] = labels[\"attention_mask\"]\n",
    "    # return model_inputs\n",
    "\n",
    "en_gr_dataset = datasets.load_dataset('wmt16', 'de-en', split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Speculative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v3kozZQNyBBQ"
   },
   "outputs": [],
   "source": [
    "class SpeculativeDecoder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_model_name = \"google-t5/t5-3b\",\n",
    "        draft_model_name = \"google-t5/t5-small\",\n",
    "        gamma = 4,\n",
    "        temperature = 1.0\n",
    "    ):\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(target_model_name)\n",
    "        self.target_model = AutoModelForSeq2SeqLM.from_pretrained(target_model_name, device_map='auto')\n",
    "\n",
    "        self.draft_model = T5ForConditionalGeneration.from_pretrained(draft_model_name, device_map='auto')\n",
    "\n",
    "        self.target_model.eval()\n",
    "        self.draft_model.eval()\n",
    "\n",
    "    def get_draft_logits(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        decoder_input_ids: torch.Tensor,\n",
    "        gamma: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Get draft logits for gamma tokens\"\"\"\n",
    "        draft_tokens = []\n",
    "        draft_probs = []\n",
    "        current_decoder_ids = decoder_input_ids\n",
    "\n",
    "        # Generate gamma tokens from the draft model\n",
    "        for _ in range(gamma):\n",
    "            with torch.no_grad():\n",
    "                outputs = self.draft_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    decoder_input_ids=current_decoder_ids,\n",
    "                    return_dict=True,\n",
    "                )\n",
    "                logits = outputs.logits[:, -1, :]  # Get logits for last position\n",
    "                probs = logits\n",
    "                # probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                token_id = torch.argmax(probs, dim=-1)\n",
    "                prob = probs.gather(-1, token_id.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "                draft_tokens.append(token_id.item())\n",
    "                draft_probs.append(prob.item())\n",
    "\n",
    "                # Update decoder inputs for next iteration\n",
    "                current_decoder_ids = torch.cat(\n",
    "                    [current_decoder_ids, token_id.view(1, 1)],\n",
    "                    dim=1\n",
    "                )\n",
    "\n",
    "                if token_id.item() == self.tokenizer.eos_token_id:\n",
    "                    break\n",
    "\n",
    "        return draft_tokens, draft_probs, outputs.logits.squeeze(0)\n",
    "\n",
    "    def get_target_probs(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        decoder_input_ids: torch.Tensor,\n",
    "        draft_tokens: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Get target probabilities for the draft tokens in parallel.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Add draft tokens to decoder input\n",
    "            full_decoder_ids = torch.cat([decoder_input_ids, draft_tokens.unsqueeze(0)], dim=1)\n",
    "            # print(input_ids_batched.shape, attention_mask_batched.shape, padded_decoder_ids.shape)\n",
    "            # decoder_mask = torch.triu(\n",
    "            #     torch.ones((full_decoder_ids.shape[1], full_decoder_ids.shape[1] + 1))\n",
    "            # )\n",
    "            # decoder_mask = decoder_mask[-(len(draft_tokens) + 1):, :-1]\n",
    "            # decoder_mask = 1 - decoder_mask\n",
    "            \n",
    "            # the shapes that we want to see are:\n",
    "            # torch.Size([11, 12]) torch.Size([1, 12])\n",
    "            # torch.Size([11, 12]) torch.Size([11, 12])\n",
    "            # torch.Size([11, 32128])\n",
    "            # torch.Size([11, 32128]) torch.Size([11, 32128])\n",
    "\n",
    "            # What im getting\n",
    "            # torch.Size([1, 12]) torch.Size([1, 12])\n",
    "            # torch.Size([1, 12]) torch.Size([1, 12])\n",
    "            # torch.Size([1, 11, 32128])\n",
    "\n",
    "\n",
    "            decoder_mask = torch.ones(full_decoder_ids.shape[1])\n",
    "            decoder_mask = decoder_mask.unsqueeze(0)\n",
    "\n",
    "\n",
    "            # print(decoder_mask.shape, full_decoder_ids.shape)\n",
    "\n",
    "            # conver to a batched input\n",
    "            # input_ids = input_ids.repeat(len(draft_tokens) + 1, 1)\n",
    "            # attention_mask = attention_mask.repeat(len(draft_tokens) + 1, 1)\n",
    "            # full_decoder_ids = full_decoder_ids.repeat(len(draft_tokens) + 1, 1)\n",
    "\n",
    "            # print(decoder_mask.shape, full_decoder_ids.shape)\n",
    "\n",
    "\n",
    "            outputs = self.target_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                decoder_input_ids=full_decoder_ids,\n",
    "                decoder_attention_mask=decoder_mask,\n",
    "                return_dict=True\n",
    "            )\n",
    "\n",
    "            \n",
    "            # dim_0_indices = torch.arange(len(draft_tokens) + 1)\n",
    "            # dim_1_indices = torch.arange(len(draft_tokens) + 1) + full_decoder_ids.shape[1] - 1 - len(draft_tokens)\n",
    "            # logits = outputs.logits[dim_0_indices, dim_1_indices, :]\n",
    "            logits = outputs.logits[:, -(len(draft_tokens) + 1):, :]\n",
    "            logits = logits.squeeze(0)\n",
    "\n",
    "            # print(logits.shape)\n",
    "            \n",
    "            # Get probabilities for positions before each draft token\n",
    "            # logits = outputs.logits[:, -(len(draft_tokens) + 1):-1, :]\n",
    "            target_probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # print(target_probs.shape, target_probs.squeeze(0).shape)\n",
    "            \n",
    "\n",
    "            return target_probs.squeeze(0), logits\n",
    "\n",
    "    def verify_tokens(\n",
    "        self,\n",
    "        target_probs: torch.Tensor,\n",
    "        draft_tokens: torch.Tensor,\n",
    "        draft_probs: torch.Tensor,\n",
    "    ) -> int:\n",
    "        \"\"\"Determine number of accepted tokens\"\"\"\n",
    "        # Get target probabilities for the draft tokens\n",
    "        # get the probabilities of the tokens at the indices of the draft tokens\n",
    "        target_probs_draft_tokens = torch.gather(target_probs, 1, draft_tokens.unsqueeze(0))\n",
    "        # Calculate acceptance ratios\n",
    "        acceptance_ratios = target_probs_draft_tokens / draft_probs.clamp(min=1e-10)\n",
    "\n",
    "        # Sample uniform random numbers \n",
    "        random_nums = torch.rand_like(acceptance_ratios)\n",
    "        acceptance_mask = random_nums <= acceptance_ratios\n",
    "\n",
    "        num_accepted = (acceptance_mask.cumsum(dim=-1) == torch.arange(1, len(acceptance_ratios) + 1)).sum().item()\n",
    "\n",
    "        return num_accepted\n",
    "\n",
    "    def translate(\n",
    "        self,\n",
    "        source_text: str,\n",
    "        max_length: int = 128\n",
    "    ) -> str:\n",
    "        \"\"\"Translate source text using speculative decoding.\"\"\"\n",
    "        # Encode source text\n",
    "        encoder_inputs = self.tokenizer(\n",
    "            f\"translate English to German: {source_text}\",\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "\n",
    "        # Initialize with start token\n",
    "        decoder_input_ids = torch.tensor([[self.tokenizer.pad_token_id]])\n",
    "\n",
    "        output = self.target_model(\n",
    "            input_ids=encoder_inputs.input_ids,\n",
    "            attention_mask=encoder_inputs.attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        probs = output.logits[:, -1, :]\n",
    "                    \n",
    "        probs = F.softmax(probs / (self.temperature + 1e-13), dim=-1)\n",
    "        token_id = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        decoder_input_ids = torch.tensor([[self.tokenizer.pad_token_id, token_id.item()]])\n",
    "\n",
    "        total_tokens = 0\n",
    "        accepted_tokens = 0\n",
    "\n",
    "        while decoder_input_ids.shape[1] < max_length:\n",
    "            # Get draft tokens autoregressively\n",
    "            draft_tokens, draft_probs, draft_logits = self.get_draft_logits(\n",
    "                encoder_inputs.input_ids,\n",
    "                encoder_inputs.attention_mask,\n",
    "                decoder_input_ids,\n",
    "                self.gamma\n",
    "            )\n",
    "\n",
    "            draft_tokens = torch.tensor(draft_tokens)\n",
    "            draft_probs = torch.tensor(draft_probs)\n",
    "\n",
    "            # softmax the draft probs\n",
    "            draft_probs = F.softmax(draft_probs / (self.temperature + 1e-13), dim=-1)\n",
    "\n",
    "            if len(draft_tokens) == 0:\n",
    "                raise ValueError(\"Draft tokens not generated.\")\n",
    "\n",
    "            # Get target probabilities in parallel\n",
    "            # start = time.time()\n",
    "            target_probs, target_logits = self.get_target_probs(\n",
    "                encoder_inputs.input_ids,\n",
    "                encoder_inputs.attention_mask,\n",
    "                decoder_input_ids,\n",
    "                draft_tokens\n",
    "            )\n",
    "            # target probs are the logits but with softmax applied\n",
    "\n",
    "            # Verify tokens\n",
    "            n_accepted = self.verify_tokens(target_probs, draft_tokens, draft_probs)\n",
    "            # Accept verified tokens\n",
    "            if n_accepted > 0:\n",
    "                decoder_input_ids = torch.cat([\n",
    "                    decoder_input_ids,\n",
    "                    draft_tokens[:n_accepted].unsqueeze(0)\n",
    "                ], dim=1)\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                # n_rejected = self.gamma - n_accepted\n",
    "                n_rejected = len(draft_tokens) - n_accepted \n",
    "                total_tokens += len(draft_tokens)\n",
    "                accepted_tokens += n_accepted\n",
    "\n",
    "                if n_rejected > 0:\n",
    "                    probs = target_logits[-n_rejected, :] #- draft_logits[1-n_rejected, :]\n",
    "                else:\n",
    "                    probs = target_logits[-1, :]\n",
    "                    \n",
    "                probs = F.softmax(probs / (self.temperature + 1e-13), dim=-1)\n",
    "                # probs /= max(self.temperature, 1e-13)\n",
    "                # probs_max = torch.where(probs > 0, probs, torch.zeros_like(probs))\n",
    "                # probs_max_sum = torch.sum(probs_max)\n",
    "                # probs = probs_max / max(probs_max_sum, 1e-13)\n",
    "                \n",
    "                token_id = torch.multinomial(probs, num_samples=1).unsqueeze(0)\n",
    "\n",
    "                decoder_input_ids = torch.cat([decoder_input_ids, token_id], dim=1)\n",
    "\n",
    "            # Check for end of sequence\n",
    "            if decoder_input_ids[0][-1].item() == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "            # # or if a full stop is generated\n",
    "            # if decoder_input_ids[0][-1].item() == self.tokenizer.convert_tokens_to_ids('.'):\n",
    "            #     break\n",
    "\n",
    "        # Decode translation\n",
    "        translation = self.tokenizer.decode(\n",
    "            decoder_input_ids[0],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        perc_accepted = accepted_tokens / total_tokens * 100\n",
    "        return translation, perc_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xonsh: For full traceback set: $XONSH_SHOW_TRACEBACK = True\n",
      "NameError: name 'AutoModelForSeq2SeqLM' is not defined\n"
     ]
    }
   ],
   "source": [
    "# just translate using the big model\n",
    "big_model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-3b\", device_map='auto')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-3b\")\n",
    "\n",
    "source_text = \"translate English to German: Formula One cars are the world's fastest regulated road-course racing cars, owing to very high cornering speeds achieved by generating large amounts of aerodynamic downforce, much of which is generated by front and rear wings.\"\n",
    "# source_text = \"translate English to German: India is also reportedly hoping for a deal on defence collaboration between the two nations.\"\n",
    "start = time.time()\n",
    "\n",
    "input_ids = tokenizer(source_text, return_tensors=\"pt\").input_ids.to(big_model.device)\n",
    "decoder_input_ids = torch.tensor([[tokenizer.pad_token_id]], device=big_model.device)  # Start with PAD token\n",
    "eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "output_tokens = []\n",
    "while True:\n",
    "    # Predict the next token\n",
    "    outputs = big_model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "    next_token_logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
    "    next_token_id = torch.argmax(next_token_logits, dim=-1)  # Greedy decoding\n",
    "\n",
    "    # Append the generated token to the decoder input\n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_token_id.unsqueeze(0)], dim=-1)\n",
    "    output_tokens.append(next_token_id.item())\n",
    "\n",
    "    # Break the loop if the EOS token is generated\n",
    "    if next_token_id.item() == eos_token_id:\n",
    "        break\n",
    "\n",
    "big_translation = tokenizer.decode(output_tokens, skip_special_tokens=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Big model translation: \", big_translation)\n",
    "print(\"Time taken: \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "speculative_decoder1 = SpeculativeDecoder(gamma=6, temperature=0.0)\n",
    "speculative_decoder2 = SpeculativeDecoder(gamma=6, temperature=0.5)\n",
    "speculative_decoder3 = SpeculativeDecoder(gamma=6, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speculative translation: Die For 1erFahrzeug sind die schnellstener reguliterenn Renwagen der, da sehr hohekeln Geschwindigkeiten erreicht, die die Erzeug von  Mengen aerocher Abungskrafterzeug, die von vorne hinten von vorne hinterngelb Flügel erzeugt werden\n",
      "Percentage tokens accepted: 19.39%\n",
      "Time taken: 6.5364 seconds\n"
     ]
    }
   ],
   "source": [
    "source_text = \"Formula One cars are the world's fastest regulated road-course racing cars, owing to very high cornering speeds achieved by generating large amounts of aerodynamic downforce, much of which is generated by front and rear wings.\"\n",
    "# source_text = \"India is also reportedly hoping for a deal on defence collaboration between the two nations.\"\n",
    "speculative_decoder1.translate(source_text)\n",
    "start = time.time()\n",
    "speculative_translation, pc = speculative_decoder1.translate(source_text)\n",
    "end = time.time()\n",
    "print(f\"Speculative translation: {speculative_translation}\")\n",
    "print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "print(f\"Time taken: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speculative translation: Die Formel 1 das amsten regulitierte Renauto der Welt aufgrund der sehr hohen Kurvengeschwindigkeiten, die durch die Erzeugung vongroßen Menge von aerodynamischer Abschwächung erzielt werden die meisten durch Vorund undflügel erzeugt werden.\n",
      "Percentage tokens accepted: 50.60%\n",
      "Time taken: 3.3020 seconds\n"
     ]
    }
   ],
   "source": [
    "# source_text = \"India is also reportedly hoping for a deal on defence collaboration between the two nations.\"\n",
    "speculative_decoder2.translate(source_text)\n",
    "start = time.time()\n",
    "speculative_translation, pc = speculative_decoder2.translate(source_text)\n",
    "end = time.time()\n",
    "print(f\"Speculative translation: {speculative_translation}\")\n",
    "print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "print(f\"Time taken: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speculative translation: Die Formel 1 ist Spitzenklasse, die weltweit am schnellsten reguliert ist, aufgrund der sehr hohen Kurvengeschwindigkeiten, die durch einen hohen aerodynamischen Abstützen erreicht werden, der größtenteil durch Vor- und Hinterflügel erzeugt wird\n",
      "Percentage tokens accepted: 84.21%\n",
      "Time taken: 2.3587 seconds\n"
     ]
    }
   ],
   "source": [
    "# source_text = \"India is also reportedly hoping for a deal on defence collaboration between the two nations.\"\n",
    "speculative_decoder3.translate(source_text)\n",
    "start = time.time()\n",
    "speculative_translation, pc = speculative_decoder3.translate(source_text)\n",
    "end = time.time()\n",
    "print(f\"Speculative translation: {speculative_translation}\")\n",
    "print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "print(f\"Time taken: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CopfVI-mjdb4"
   },
   "outputs": [],
   "source": [
    "class NormalDecoder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"google-t5/t5-3b\",\n",
    "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    ):\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize tokenizer and model\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        # self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map='auto')\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_logits(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        decoder_input_ids: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Get logits from model for the last token.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                return_dict=True\n",
    "            )\n",
    "            return outputs.logits[:, -1, :]\n",
    "\n",
    "    def sample_token(self, logits: torch.Tensor, temperature: float = 1.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Sample a token from logits using temperature sampling.\"\"\"\n",
    "        if temperature == 0:\n",
    "            # Greedy sampling\n",
    "            token_id = torch.argmax(logits, dim=-1)\n",
    "            prob = torch.ones_like(token_id, dtype=torch.float)\n",
    "        else:\n",
    "            # Temperature sampling\n",
    "            probs = F.softmax(logits / temperature, dim=-1)\n",
    "            token_id = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "            prob = probs.gather(-1, token_id.unsqueeze(-1)).squeeze(-1)\n",
    "        return token_id, prob\n",
    "\n",
    "    def translate(\n",
    "        self,\n",
    "        source_text: str,\n",
    "        max_length: int = 128,\n",
    "        temperature: float = 0.7\n",
    "    ) -> str:\n",
    "        \"\"\"Translate source text using the normal T5 model.\"\"\"\n",
    "        # Encode source text\n",
    "        encoder_inputs = self.tokenizer(\n",
    "            f\"translate English to German: {source_text}\",\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Initialize decoder input with start token\n",
    "        decoder_input_ids = torch.tensor([[self.tokenizer.pad_token_id]], device=self.device)\n",
    "\n",
    "        while decoder_input_ids.shape[1] < max_length:\n",
    "            # Generate logits for the next token\n",
    "            logits = self.get_logits(\n",
    "                encoder_inputs.input_ids,\n",
    "                encoder_inputs.attention_mask,\n",
    "                decoder_input_ids\n",
    "            )\n",
    "\n",
    "            # Sample a token\n",
    "            token_id, _ = self.sample_token(logits, temperature)\n",
    "\n",
    "            # Add token to the decoder input\n",
    "            decoder_input_ids = torch.cat(\n",
    "                [decoder_input_ids, token_id.view(1, 1)],\n",
    "                dim=1\n",
    "            )\n",
    "\n",
    "            # Break if end token is generated\n",
    "            if token_id.item() == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "        # Decode and return translation\n",
    "        translation = self.tokenizer.decode(\n",
    "            decoder_input_ids[0],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        return translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speculative_decoder = SpeculativeDecoder()\n",
    "# normal_decoder = NormalDecoder()\n",
    "\n",
    "# source_text = \"He said Lamb made the fateful 911 call sometime after that.\" # spec does not work\n",
    "\n",
    "# speculative_decoder.translate(source_text)\n",
    "# start = time.time()\n",
    "# speculative_translation, pc = speculative_decoder.translate(source_text)\n",
    "# end = time.time()\n",
    "# print(f\"Speculative translation: {speculative_translation}\")\n",
    "# print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "# print(f\"Time taken: {end - start:.4f} seconds\")\n",
    "\n",
    "# start = time.time()\n",
    "# normal_translation = normal_decoder.translate(source_text)\n",
    "# end = time.time()\n",
    "# print(f\"Normal translation: {normal_translation}\")\n",
    "# print(f\"Time taken: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwtUoGDUjiSD",
    "outputId": "2a92f134-5a76-45b9-884b-51515d57fa4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:03<01:31,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India and Japan prime ministers meet in Tokyo\n",
      "Normal Translation: Indiens und Japans Premierminister treffen sich in Tokio\n",
      "Time taken: 1.42 seconds\n",
      "Speculative Translation: Indien und Japans Premierminister treffen sich Tokio\n",
      "Time taken: 1.73 seconds\n",
      "Percentage tokens accepted: 68.75%\n",
      "Target: Die Premierminister Indiens und Japans trafen sich in Tokio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:11<02:51,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\n",
      "Normal Translation: Der neue indische Ministerpräsident Narendra Modi trifft in Tokio auf seinem ersten großen Auslandsbesuch nach dem Wahlsieg im Mai mit seinem japanischen Amtskollegen Shinzo Abe, um über die wirtschaftlichen und Sicherheitsbeziehungen zu sprechen.\n",
      "Time taken: 5.71 seconds\n",
      "Speculative Translation: In Indiens neuer Premierminister Narendra Modi trifft sein japanisches Amtkollege Shinzo Ab, um über wirtschaftliche und Sicherheitsbeziehungen zu diskutieren, und das in seinemersten großen Auslandsbesuch seit dem Wahlsieg im Mai.\n",
      "Time taken: 2.47 seconds\n",
      "Percentage tokens accepted: 81.97%\n",
      "Target: Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:16<02:27,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.\n",
      "Normal Translation: Herr Modi ist auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen zu der drittgrößten Volkswirtschaft der Welt zu verstärken.\n",
      "Time taken: 3.25 seconds\n",
      "Speculative Translation: Herr Modi ist auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen zurdrittgrößten Volkswirtschaft Welt zu stärke.\n",
      "Time taken: 1.47 seconds\n",
      "Percentage tokens accepted: 80.00%\n",
      "Target: Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:18<01:48,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: High on the agenda are plans for greater nuclear co-operation.\n",
      "Normal Translation: Eine hohe Priorität besitzt das Vorhaben einer verstärkten nuklearen Zusammenarbeit.\n",
      "Time taken: 1.56 seconds\n",
      "Speculative Translation: Zu den Schwerpunkten der Agenda gehören die mehr Zusammenarbeit im Bereich der Kernenergie.\n",
      "Time taken: 0.59 seconds\n",
      "Percentage tokens accepted: 100.00%\n",
      "Target: Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:21<01:39,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India is also reportedly hoping for a deal on defence collaboration between the two nations.\n",
      "Normal Translation: Das Land hofft, ebenfalls künftig mit China eine Zusammenarbeit im Bereich der Verteidigungstechnik eingehen zu können.\n",
      "Time taken: 2.42 seconds\n",
      "Speculative Translation: Indien hofft ebenfalls auf eine Vereinbarung über die der Verteidigungszusammenarbeit zwischen den beiden Nationen.\n",
      "Time taken: 1.22 seconds\n",
      "Percentage tokens accepted: 86.67%\n",
      "Target: Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:26<01:39,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha police arrest 20-year-old after high speed motorcycle chase\n",
      "Normal Translation: Die Karratha-Polizei verhaftet einen 20-Jährigen nach einer Radjagd\n",
      "Time taken: 1.90 seconds\n",
      "Speculative Translation: InternationalesKonferenztreffen inratha-urkundlicher ffentlichkeitkontakte der deutschen mit demösterreichischen Ministerpräsidenten Schweiz.\n",
      "Time taken: 2.59 seconds\n",
      "Percentage tokens accepted: 30.43%\n",
      "Target: Polizei von Karratha verhaftet 20-Jährigen nach schneller Motorradjagd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:31<01:44,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A motorcycle has been seized after it was ridden at 125km/h in a 70km/h zone and through bushland to escape police in the Pilbara.\n",
      "Normal Translation: Das Foto der Autobahn A1 in Düsseldorf zeigt das Auto auf einer Bahn mit druckvoller Aufschrift \"Wendiger Autobahn\" auf der Straßenseite.\n",
      "Time taken: 3.03 seconds\n",
      "Speculative Translation: Mittlerweile wurde ein Motorrad erworben, nachdem es in einer 70 km/h Zone weiter  und durch Buschlandgefahren wurde um der Polizei der Pilbara zuentkommen.\n",
      "Time taken: 2.34 seconds\n",
      "Percentage tokens accepted: 62.71%\n",
      "Target: Ein Motorrad wurde beschlagnahmt, nachdem der Fahrer es mit 125 km/h in einer 70 km/h-Zone und durch Buschland gefahren hatte, um der Polizei in Bilbara zu entkommen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:36<01:43,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Traffic police on patrol in Karratha this morning tried to pull over a blue motorcycle when they spotted it reaching 125km/h as it pulled out of a service station on Bathgate Road.\n",
      "Normal Translation: Seit heute ist es auch einmal im 50jährigen Jubiläum der ersten große PR-Kampagne der Firma AGI (Australian Geographic Information Agency).\n",
      "Time taken: 2.79 seconds\n",
      "Speculative Translation: Unfallsberichte von vielen RC-Anhängern, Fahrer und Fahrer die esgeschickt haben,Empfänger zu schicken haben Grund für die nderung derRegeln.\n",
      "Time taken: 2.21 seconds\n",
      "Percentage tokens accepted: 60.38%\n",
      "Target: Verkehrspolizisten in Karratha versuchten heute morgen, ein blaues Motorrad zu stoppen, nachdem sie es dabei beobachtet hatten, wie es mit 125 km/h eine Tankstelle auf der Bathdate Road verließ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:44<02:01,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Police say the rider then failed to stop and continued on to Burgess Road before turning into bushland, causing the officers to lose sight of it.\n",
      "Normal Translation: Nach Angaben der Polizei hat der Fahrer die Haltestelle verfehlt und fuhr auf die Burgess Road weiter, bevor er sich in Buschland verwandelte und die Polizeibeamten den Fahrer aus den Augen verloren.\n",
      "Time taken: 4.74 seconds\n",
      "Speculative Translation: Schon damalsfand der Fahrer dieinstitutiven Regeln, die heutztage ergriffen wurden. Ganz im Gegenteil,fanden die ersten Regeln der Regeln, die er erkannte. Ein großer Teil der Regeln, Bedingung und ffentlichkeit, wurden von den verschiedenengesellschaftlichen Gruppen erarbeitt\n",
      "Time taken: 3.52 seconds\n",
      "Percentage tokens accepted: 72.41%\n",
      "Target: Die Polizei berichtet, dass der Fahrer die Haltesignale dann ignorierte und weiter auf der Burgess Road fuhr, bevor er in das Buschland abbog, wo die Beamten es aus den Augen verloren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:49<01:47,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle and a person matching the description of the rider was then spotted at a house on Walcott Way in Bulgarra.\n",
      "Normal Translation: Das Motorrad und eine Person, die der Beschreibung des Fahrers entsprach, wurden dann in einem Haus auf der Walcott Way in Bulgarra gesehen.\n",
      "Time taken: 2.98 seconds\n",
      "Speculative Translation: B. ein Motorrad und eine Person, die der Beschreibung des Fahrers entspricht, wurde bei einem Haus auf der Walcott Way in Bulgarra gesehen.\n",
      "Time taken: 1.36 seconds\n",
      "Percentage tokens accepted: 82.86%\n",
      "Target: Das Motorrad sowie eine Person, die der Beschreibung des Fahrers entsprach wurden später bei einem Haus im Walcott Way in Bulgarra gesehen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:53<01:36,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha Police have charged a 20-year-old man with failing to stop and reckless driving.\n",
      "Normal Translation: In den letzten Wochen hat die Polizei in Karratha einen 20-jährigen Mann wegen Nichtanhaltens und Fahrverhaltensverbrechen verhaftet.\n",
      "Time taken: 2.95 seconds\n",
      "Speculative Translation: Sinatra hat einen 20-jährigen Mannwegen angeklag fürfahrlässiges Fahren und Nichthaltevermögen an den Tag gelegt\n",
      "Time taken: 1.57 seconds\n",
      "Percentage tokens accepted: 59.52%\n",
      "Target: Die Polizei von Karratha beschuldigt einen 20-jährigen Mann der Nichtbeachtung eines Haltesignals sowie rücksichtslosen Fahrens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:59<01:36,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is due to appear in Karratha Magistrates Court on September 23.\n",
      "Normal Translation: Der Fall steht noch an, und er wird am 23. September vor dem Gericht in Karratha erscheinen.\n",
      "Time taken: 1.99 seconds\n",
      "Speculative Translation: Im letzten Jahrtrafen hat er die afrikanische Regierung angekt. 2004 hater seinenDienst als Präsident dervergleichungorganisation kodiniert. Anders als in der letzten Zeit hatte er gleich zwei Jahre in der deutschen Regierung.\n",
      "Time taken: 3.92 seconds\n",
      "Percentage tokens accepted: 50.51%\n",
      "Target: Er soll am 23. September vor dem Amtsgericht in Karratha erscheinen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [01:01<01:13,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle was seized and impounded for three months.\n",
      "Normal Translation: Das Motorrad war für drei Monate aufbewahrt worden.\n",
      "Time taken: 1.22 seconds\n",
      "Speculative Translation: Das Motorrad wurde beschlagnahmt und drei Monate lang beschlagnahmt.\n",
      "Time taken: 0.70 seconds\n",
      "Percentage tokens accepted: 100.00%\n",
      "Target: Das Motorrad wurde sichergestellt und für drei Monate beschlagnahmt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:05<01:04,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster accused of Nairn and Pitlochry hotel rapes\n",
      "Normal Translation: George Webster beschuldigte sich der Vergewaltigung von Frauen in Hotels in Nairn und Pitlochry\n",
      "Time taken: 2.25 seconds\n",
      "Speculative Translation: George Webster hat der Vergewaltigung von Hotelgästen in Nair und Pitlochry beschuldigt\n",
      "Time taken: 1.08 seconds\n",
      "Percentage tokens accepted: 82.14%\n",
      "Target: George Webster wegen Hotelvergewaltigungen in Naim und Pitlochry angeklagt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:08<00:58,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A man is to stand trial accused of raping women at two hotels.\n",
      "Normal Translation: Ein Mann soll vor Gericht gestellt werden, der der Vergewaltigung von Frauen in zwei Hotels beschuldigt wurde.\n",
      "Time taken: 2.24 seconds\n",
      "Speculative Translation: Die Präsidentschafthat sichentschlossen, die Präsidentschaft zu zitieren, um die Präsidentschaft zu erheben.\n",
      "Time taken: 1.29 seconds\n",
      "Percentage tokens accepted: 70.59%\n",
      "Target: Ein Mann steht wegen der Vergewaltigung von Frauen in zwei Hotels vor Gericht.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:13<00:58,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster, 28, faced the charges during a hearing at the High Court in Glasgow.\n",
      "Normal Translation: Das Urteil bezieht sich auf zwei Bruttoinfektionen, die in den späten 90er Jahren mit einem Schadensersatz von 20.000 Euro erzielt wurden.\n",
      "Time taken: 3.21 seconds\n",
      "Speculative Translation: Als er mit demdeutschen Staatsgericht in seinen ersten Wahlen in der Bulgarien kämpfte, floh er sich in der Innenstadt von Glasgow an.\n",
      "Time taken: 1.79 seconds\n",
      "Percentage tokens accepted: 68.75%\n",
      "Target: George Webster, 28, wurde die Anklage bei einer Anhörung von dem Obersten Gericht in Glasgow verlesen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [01:17<00:53,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is alleged to have raped a woman at the Scotland's Hotel in Pitlochry in Perthshire on June 7, 2013.\n",
      "Normal Translation: Er soll eine Frau im Scotland's Hotel in Pitlochry in Perthshire am 7. Juni 2013 vergewaltigt haben.\n",
      "Time taken: 2.38 seconds\n",
      "Speculative Translation: Im letzten Jahrleisten sie sich für die deutsche Polizei und die deutsche Polizei Weimar derzeit verantwortlich Wiesbaden.\n",
      "Time taken: 1.43 seconds\n",
      "Percentage tokens accepted: 68.57%\n",
      "Target: Er wird beschuldigt, am 7. Juni 2013 eine Frau im Scotland's Hotel in Pitlochry in Perthshire vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [01:24<00:59,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: It is claimed Webster attacked her while she was \"unconscious, asleep and incapable of giving consent.\"\n",
      "Normal Translation: Einer der Hauptgründungen für diesen Anschlag war die Verwandlung von Sex - und „Harry Potter“ – in eine brennende Serie von Thrillern, die sich um die Macht der Eroberer drehten.\n",
      "Time taken: 5.27 seconds\n",
      "Speculative Translation: Der Name Webster  vom erstenphonischen Film''leitet sich von der ersten Serie inpiriert.\n",
      "Time taken: 1.65 seconds\n",
      "Percentage tokens accepted: 45.24%\n",
      "Target: Die Anklage lautet, dass Webster sie angriff, während sie \"bewusstlos war, schlief, und kein Einverständnis signalisieren konnte.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:28<00:52,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Webster is then charged with raping a second woman at the Golf View Hotel in Nairn in the Highlands on May 4, 2014.\n",
      "Normal Translation: Webster ist dann beschuldigt mit Vergewaltigung einer zweiten Frau im Golf View Hotel in Nairn im Highlands am 4. Mai 2014.\n",
      "Time taken: 2.82 seconds\n",
      "Speculative Translation: Seit Morgen hat Webster eine zweite Frau vergewaltigt, die am 4. Mai 2014 im Golf View Hotel in Nairn im Highlands vergewaltigt wurde.\n",
      "Time taken: 1.55 seconds\n",
      "Percentage tokens accepted: 82.50%\n",
      "Target: Webster wird darüber hinaus vorgeworfen, am 4. Mai 2014 eine zweite Frau im Golf View Hotel in Naim im schottischen Hochland vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:32<00:44,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Judge Lady Rae set a trial date for November 17 at the High Court in Edinburgh.\n",
      "Normal Translation: Die Richterin Lady Rae legte einen Termin für das Verfahren am 17. November vor dem High Court von Edinburgh.\n",
      "Time taken: 2.08 seconds\n",
      "Speculative Translation: Während der letzten Zeit hat die Richterin Ladye Ra zu einem Verfahrensdatum für den 17. November vor dem Hohen Gericht von Edinburgh geführt\n",
      "Time taken: 1.53 seconds\n",
      "Percentage tokens accepted: 70.00%\n",
      "Target: Richterin Lady Rae setzte den Verhandlungstermin für den 17. November am Obersten Gericht in Edinburgh an.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:35<00:36,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Reconnecting With the Very American Ideal That Labor Rights Are Human Rights\n",
      "Normal Translation: Wiederherstellung des sehr amerikanischen Ideals, dass die Arbeitsrechte Menschenrechte sind\n",
      "Time taken: 1.73 seconds\n",
      "Speculative Translation: Wiederherstellung der Verbindung der Arbeitsrechte mit dem amerikanische Ideal, dass dierechte der Arbeitnehmer Menschenrecht sind\n",
      "Time taken: 1.42 seconds\n",
      "Percentage tokens accepted: 52.78%\n",
      "Target: Rückbesinnung auf das sehr amerikanische Ideal der Arbeitsrechte als Menschenrechte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:39<00:33,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Congressmen Keith Ellison and John Lewis have proposed legislation to protect union organizing as a civil right.\n",
      "Normal Translation: Die Kongressabgeordneten Keith Ellison und John Lewis haben Gesetzesvorlagen vorgelegt, die die Organisation von Gewerkschaften als ein Bürgerrecht schützen.\n",
      "Time taken: 3.21 seconds\n",
      "Speculative Translation: Vertreter des Kongresse, Keith Ellison und John Lewis, haben Gesetze vorgeschlagen, um Gewerkschaftsorganisationen als Bürgerrecht zu schützen\n",
      "Time taken: 1.26 seconds\n",
      "Percentage tokens accepted: 84.38%\n",
      "Target: Die Kongressabgeordneten Keith Ellison und John Lewis haben einen Gesetzesvorschlag eingebracht, um die Organisation von Gewerkschaften als Bürgerrecht zu etablieren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:46<00:34,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: \"As go unions, so go middle-class jobs,\" says Ellison, the Minnesota Democrat who serves as a Congressional Progressive Caucus co-chair.\n",
      "Normal Translation: „Wenn die Gewerkschaften verschwinden, so gehen auch die Arbeitsplätze der Mittelschicht\", sagt Ellison, der Demokrat aus Minnesota, der der Ko-Vorsitzende des Progressiven Caucus im Kongress ist.\n",
      "Time taken: 4.74 seconds\n",
      "Speculative Translation: \"So wie Gewerkschaften gehen, so die Arbeit der Mittelschicht\", sagt Ellison, der Demokrat in Minnesota, der als Mitvorsitzender des Progressiven Kongresse im Kongress fungiert.\n",
      "Time taken: 1.88 seconds\n",
      "Percentage tokens accepted: 77.55%\n",
      "Target: \"So wie Gewerkschaften sterben, sterben auch die Mittelklassejobs,\" sagte Ellison, ein Demokrat aus Minnesota und stellvertretender Vorsitzender des Progressive Caucus im Kongress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:50<00:27,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: That's why I'm proud to introduce the Employee Empowerment Act with civil rights icon John Lewis.\n",
      "Normal Translation: Deshalb bin ich stolz, mit der amerikanischen Ikone der Bürgerrechte John Lewis das Employee Empowerment Act vorstellen zu können.\n",
      "Time taken: 2.71 seconds\n",
      "Speculative Translation: Deswegen bin ich stolz, das Employee Empowerment Act mit dem Bürgerrechtsikon John Lewis einzuführen.\n",
      "Time taken: 0.95 seconds\n",
      "Percentage tokens accepted: 100.00%\n",
      "Target: Daher stelle ich stolz gemeinsam mit der Bürgerrechtsikone John Lewis das Mitarbeiterermächtigungsgesetz vor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [01:58<00:27,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: This ground-breaking legislation will give workers the same legal options for union organizing discrimination as for other forms of discrimination - stopping anti-union forces in their tracks\n",
      "Normal Translation: Diese bahnbrechende Gesetzgebung wird den Arbeitnehmern die gleichen rechtlichen Möglichkeiten für die Diskriminierung aufgrund der Gewerkschaftsorganisation wie für andere Formen der Diskriminierung bieten und so gewerkschaftsfeindliche Kräfte aufhalten.\n",
      "Time taken: 5.38 seconds\n",
      "Speculative Translation: Dieser bahnbrechende Gesetzgeber wird den Arbeitnehmern die gleichen rechtlichen für die Organisation vonkriminellen Diskriierungen bieten für andere Formen der Diskriminierung - die Gewerkschaftsfeindlichkeit in ihren Spuren zu stoppen\n",
      "Time taken: 2.60 seconds\n",
      "Percentage tokens accepted: 74.63%\n",
      "Target: Dieses bahnbrechende Gesetz gibt Arbeitern die gleichen rechtlichen Möglichkeiten bei Diskriminierung wegen der Organisation von Gewerkschaften wie bei anderen Formen der Diskriminierung - und stoppt so antigewerkschaftlich eingestellte Kräfte.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [02:08<00:28,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Amending the National Labor Relations Act to allow workers who face discrimination for engaging in union organizing to sue for justice in the civil courts - and to collect compensatory and punitive damages - is a sound and necessary initiative.\n",
      "Normal Translation: So gestattet eine nderung des National Labor Relations Act, dass Arbeitnehmern, die wegen der Teilnahme an gewerkschaftlichen Aktivitäten diskriminiert werden, das Recht zugestanden wird, bei zivilgerichtlichen Instanzen rechtliche Schritte einzuleiten und Entschädigungs- und Schadenersatz zu fordern, eine solide und notwendige Initiative.\n",
      "Time taken: 7.09 seconds\n",
      "Speculative Translation: Bei dernderung des Nationalen Arbeitsbeziehungsgesetze, das Arbeitnehmern, Beschäftigten, die Diskriminierung wegen ihrer Gewerkschaftsorganisationen ausgesetzt sind, die Möglichkeit zu geben, vor Zivilgerichten um Gerechtigkeit zu verklagen- und Entschädigungs- Strafschädigung zu erheben, ist eine gute und notwendige Initiative.\n",
      "Time taken: 3.78 seconds\n",
      "Percentage tokens accepted: 70.83%\n",
      "Target: Die Ergänzung des nationalen Arbeitsrechtsgesetzes, um eine Möglichkeit für einer Diskriminierung ausgesetzte Arbeitern zur Organisation einer Gewerkschaftsvertretung zu schaffen, um vor einem Zivilgericht um Gerechtigkeit zu klagen - und um Schadensersatz oder Strafgelder zu erhalten - ist eine sinnvolle und notwendige Initiative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [02:12<00:17,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: But it in certainly not a radical initiative - at least by American standards.\n",
      "Normal Translation: Doch ist dies gewiss keine radikale Initiative - zumindest nicht nach amerikanischen Standards.\n",
      "Time taken: 2.16 seconds\n",
      "Speculative Translation: Aber e ist sicherlich radikal, zumindest Amerikas.\n",
      "Time taken: 1.02 seconds\n",
      "Percentage tokens accepted: 53.85%\n",
      "Target: Aber es ist mit Sicherheit keine radikale Initiative - jedenfalls nicht nach amerikanischen Standards.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [02:18<00:12,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Indeed, the best way to understand what Ellison, Lewis and the cosponsors of their legislation are proposing is as a reconnection with a very American idea.\n",
      "Normal Translation: Tatsächlich ist das, was Ellison, Lewis und die Mitbegründer ihrer Gesetzesvorlage vorschlagen, beispielhaft als eine Wiederanbindung an eine höchst amerikanische Idee zu verstehen.\n",
      "Time taken: 4.22 seconds\n",
      "Speculative Translation: Tatsächlich ist die beste Art, verstehen zu können was Ellison, Lewis und die Mittragenden ihrer Gesetzgebung vorschlagen, eine Verknüpfung mit einer sehr amerikanischen Idee.\n",
      "Time taken: 2.05 seconds\n",
      "Percentage tokens accepted: 76.47%\n",
      "Target: Tatsächlich ist die beste Art und Weise zum Verständnis dessen, was Ellison, Lewis und die weiteren Sponsoren ihrer Gesetzesvorlage vorschlagen, die Verbindung zurück zu einer sehr amerikanischen Idee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [02:28<00:07,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Despite the battering that unions have taken in recent years - in Wisconsin, Michigan and states across the country - Americans once encouraged countries around the world to embrace, extend and respect labor rights.\n",
      "Normal Translation: Trotz des heftigen Schlags, den Gewerkschaften in den letzten Jahren erlitten haben - in Wisconsin, Michigan und in ganzen Bundesstaaten - ermutigten Amerikaner einst Länder auf der ganzen Welt, Arbeitsrechte zu akzeptieren, auszubauen und zu respektieren.\n",
      "Time taken: 7.03 seconds\n",
      "Speculative Translation: Trotz der erschütternden Anschläge, die die Gewerkschaften in denletzten Jahren - in Wisconsin, Michigan und in Bundesstaaten überall im Land - ergriffen haben,ermunterten die Amerikaner Länder auf deren Welt, ihre Arbeitsrechte zu berücksichtig, auszuweiten und achten\n",
      "Time taken: 3.41 seconds\n",
      "Percentage tokens accepted: 69.77%\n",
      "Target: Trotz der Rückschläge, denen die Gewerkschaften in den vergangenen Jahren ausgesetzt waren - in Wisconsin, Michigan und anderen Staaten im ganzen Land - haben Amerikaner einst Länder in aller Welt dazu ermutigt, Arbeitsrechte anzuerkennen, auszuweiten und einzuhalten.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:35<00:00,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: There was a time, within the living memory of millions of Americans, when this country championed democracy, freedom of speech, freedom of the press and the right to organize in the same breath.\n",
      "Normal Translation: Es gab eine Zeit, die Millionen von Amerikanern noch in frischer Erinnerung hat, als dieses Land gleichzeitig Demokratie, Meinungsfreiheit, Pressefreiheit und das Recht auf Vereinigungsfreiheit verteidigte.\n",
      "Time taken: 4.68 seconds\n",
      "Speculative Translation: Es gab eine Zeit, in der Millionen von Amerikanern leben, als dieses Land Demokrati, Redfreiheit, Pressefreiheit und das Recht auf Organisation im gleichen Atemzug unterstützte\n",
      "Time taken: 1.81 seconds\n",
      "Percentage tokens accepted: 80.00%\n",
      "Target: Es gab eine Zeit, an die sich Millionen von Amerikanern noch erinnern, als dieses Land Demokratie, Redefreiheit, Pressefreiheit und das Vereinigungsrecht in einem Atemzug nannte.\n",
      "\n",
      "Average time taken for normal decoding: 3.31 seconds\n",
      "Average time taken for speculative decoding: 1.87 seconds\n",
      "Average speedup over 30 iterations: 1.76x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize decoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "speculative_decoder = SpeculativeDecoder(gamma=7, temperature=1.0)\n",
    "normal_decoder = NormalDecoder()\n",
    "\n",
    "spec_total_time = 0\n",
    "normal_total_time = 0\n",
    "total_iters = 0\n",
    "\n",
    "for i in tqdm(en_gr_dataset['translation'][:30]):\n",
    "    source_text = i['en']\n",
    "    target_text = i['de']\n",
    "    \n",
    "    # Time the translation\n",
    "    start_time = time.time()\n",
    "    spec_translation, pc = speculative_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    spec_time = end_time - start_time\n",
    "\n",
    "    # spec_total_time += spec_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    normal_translation = normal_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    normal_time = end_time - start_time\n",
    "\n",
    "    # normal_total_time += normal_time\n",
    "\n",
    "    print(f\"Source: {source_text}\")\n",
    "    print(f\"Normal Translation: {normal_translation}\")\n",
    "    print(f\"Time taken: {normal_time:.2f} seconds\")\n",
    "    print(f\"Speculative Translation: {spec_translation}\")\n",
    "    print(f\"Time taken: {spec_time:.2f} seconds\")\n",
    "    print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "    \n",
    "    print(f\"Target: {target_text}\")\n",
    "\n",
    "    # if normal_time - spec_time > -0.1:\n",
    "    spec_total_time += spec_time\n",
    "    normal_total_time += normal_time\n",
    "    total_iters += 1\n",
    "\n",
    "print(f\"\\nAverage time taken for normal decoding: {normal_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average time taken for speculative decoding: {spec_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average speedup over {total_iters} iterations: {normal_total_time / spec_total_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "  3%|▎         | 1/30 [00:03<01:47,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India and Japan prime ministers meet in Tokyo\n",
      "Normal Translation: Indien und Japan treffen sich in Tokio\n",
      "Time taken: 0.96 seconds\n",
      "Speculative Translation: Indien und Japans Premierminister treffen sich Tokio\n",
      "Time taken: 2.75 seconds\n",
      "Percentage tokens accepted: 68.75%\n",
      "Target: Die Premierminister Indiens und Japans trafen sich in Tokio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:14<03:46,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\n",
      "Normal Translation: Indiens neuer Ministerpräsident Narendra Modi trifft in Tokio auf seinem ersten großen Auslandsbesuch seit dem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe, um wirtschaftliche und Sicherheitsbeziehungen zu besprechen.\n",
      "Time taken: 5.30 seconds\n",
      "Speculative Translation: Die deutsche Regierung, die Präsidentin UNF hat, hat sich mit den Präsidenten der Europäische Union in der Europäische Union angehört, die sich mit der Europäische Transportunion befassen. Glaubwürdigkeit die Europäische Union, dieVielen zu erm glichen, die Europäische Union zugen hat, und dieEuropäische Unionhat sich mit der Europäische Union befass, die Arbeit der Europäische Union zuerkann.\n",
      "Time taken: 5.84 seconds\n",
      "Percentage tokens accepted: 54.17%\n",
      "Target: Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:19<02:52,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.\n",
      "Normal Translation: Herr Modi ist auf einer fünftägigen Reise nach Japan, um die Wirtschaftsbeziehungen zur drittgrößten Volkswirtschaft der Welt zu stärken.\n",
      "Time taken: 2.92 seconds\n",
      "Speculative Translation: Herr Modi ist auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen zurdrittgrößten Volkswirtschaft Welt zu stärke.\n",
      "Time taken: 1.43 seconds\n",
      "Percentage tokens accepted: 80.00%\n",
      "Target: Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:21<02:06,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: High on the agenda are plans for greater nuclear co-operation.\n",
      "Normal Translation: Es stehen Pläne für eine verstärkte nukleare Zusammenarbeit ganz oben auf der Tagesordnung.\n",
      "Time taken: 1.60 seconds\n",
      "Speculative Translation: Hier stehen Pläne für einee verstärkt nukleare Zusammenarbeit auf der Tagesordnung.\n",
      "Time taken: 0.91 seconds\n",
      "Percentage tokens accepted: 63.64%\n",
      "Target: Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:26<01:56,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India is also reportedly hoping for a deal on defence collaboration between the two nations.\n",
      "Normal Translation: In Indien wird angeblich auch ein Abkommen über die Zusammenarbeit auf dem Gebiet der Verteidigung zwischen den beiden Nationen erhofft.\n",
      "Time taken: 2.79 seconds\n",
      "Speculative Translation: Jedoch hoffe Indiena ebenfalls auf eine Vereinbarung über die Zusammenarbeit im Verteidigungbereich zwischen den beiden Nation.%\n",
      "Time taken: 1.53 seconds\n",
      "Percentage tokens accepted: 60.53%\n",
      "Target: Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:29<01:39,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha police arrest 20-year-old after high speed motorcycle chase\n",
      "Normal Translation: Die Polizei von Karratha verhaftet einen 20-jährigen Nach einer hohen Geschwindigkeit auf dem Motorrad\n",
      "Time taken: 1.87 seconds\n",
      "Speculative Translation: Im Jahr 2000trafen die deutsche Polizei in der Nähe von Karratha in der Nähe des öffentlichen Nahsektors.\n",
      "Time taken: 1.26 seconds\n",
      "Percentage tokens accepted: 72.73%\n",
      "Target: Polizei von Karratha verhaftet 20-Jährigen nach schneller Motorradjagd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:35<01:53,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A motorcycle has been seized after it was ridden at 125km/h in a 70km/h zone and through bushland to escape police in the Pilbara.\n",
      "Normal Translation: Die Europäische Union hat am Montag angekündigt, es könnten bis zum 1. Juli 2009 drei Millionen Menschen über die Straße ins Gefängnis versetzt werden.\n",
      "Time taken: 3.68 seconds\n",
      "Speculative Translation: Eine Motorrad wurde beschlagnahm, nachdeme sie mit125 km/h in einer 70/km/-Zone gereist war und durch Buschlandgefahren wurde um der Polizei in Pilbar zu entkommen.\n",
      "Time taken: 2.81 seconds\n",
      "Percentage tokens accepted: 52.00%\n",
      "Target: Ein Motorrad wurde beschlagnahmt, nachdem der Fahrer es mit 125 km/h in einer 70 km/h-Zone und durch Buschland gefahren hatte, um der Polizei in Bilbara zu entkommen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:43<02:05,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Traffic police on patrol in Karratha this morning tried to pull over a blue motorcycle when they spotted it reaching 125km/h as it pulled out of a service station on Bathgate Road.\n",
      "Normal Translation: Die Verkehrspolizei in Karratha hat heute früh versucht, ein blaues Motorrad zu retten, als sie es gerade auf eine Tankstelle in der Bathgate Road fuhr, 125km/h.\n",
      "Time taken: 4.60 seconds\n",
      "Speculative Translation: Die Polizei in Karrathahat heute Morgen versucht, einblaue Motor auszuziehen als sie sah, dass der Motorrad 125 km/h be, alser aus einer Servicestation der Bathgate Road zog.\n",
      "Time taken: 2.86 seconds\n",
      "Percentage tokens accepted: 49.35%\n",
      "Target: Verkehrspolizisten in Karratha versuchten heute morgen, ein blaues Motorrad zu stoppen, nachdem sie es dabei beobachtet hatten, wie es mit 125 km/h eine Tankstelle auf der Bathdate Road verließ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:51<02:15,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Police say the rider then failed to stop and continued on to Burgess Road before turning into bushland, causing the officers to lose sight of it.\n",
      "Normal Translation: Aufgrund des hohen Ausmaßes der Unfallschäden entschied der Ausschuss der Europäischen Polizei für Gerüchte, die einen Verdacht auf Gefährdung von Landwirten und Schutztieren aufgrund der Unfalles der PKW-Fahrer auf sich ziehen.\n",
      "Time taken: 5.72 seconds\n",
      "Speculative Translation: Das heißt die Polizei sagt, der Fahrer sei dann nicht angehalten undfuhr weiter Burgess Road, bevor er sich in Buschland verwandelte, was die Offiziere aus dem Auge zog.\n",
      "Time taken: 2.33 seconds\n",
      "Percentage tokens accepted: 66.67%\n",
      "Target: Die Polizei berichtet, dass der Fahrer die Haltesignale dann ignorierte und weiter auf der Burgess Road fuhr, bevor er in das Buschland abbog, wo die Beamten es aus den Augen verloren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:55<01:55,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle and a person matching the description of the rider was then spotted at a house on Walcott Way in Bulgarra.\n",
      "Normal Translation: Das Motorrad und eine Person, deren Beschreibung dem des Fahrers entspricht, wurden dann an einem Haus auf der Walcott Way in Bulgarra gesehen.\n",
      "Time taken: 2.85 seconds\n",
      "Speculative Translation: Auf der Walcott Way in Bulgarra wurde das Motorrad und eine Person, die der Beschreibung des Fahrers entspricht, dann in einem gefundenen Haus gesehen\n",
      "Time taken: 1.33 seconds\n",
      "Percentage tokens accepted: 82.35%\n",
      "Target: Das Motorrad sowie eine Person, die der Beschreibung des Fahrers entsprach wurden später bei einem Haus im Walcott Way in Bulgarra gesehen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:59<01:40,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha Police have charged a 20-year-old man with failing to stop and reckless driving.\n",
      "Normal Translation: Die Polizei in Karlratha hat einen 20-jährigen Mann mit Fahrvergehen und vorsätzlichem Fahrverhalten beschuldigt.\n",
      "Time taken: 2.47 seconds\n",
      "Speculative Translation: Zur Karha-Polizei ein 20-jähriger Mann hat eine rücksichnehmende und rücksichlose Beförderung angelagt.\n",
      "Time taken: 1.75 seconds\n",
      "Percentage tokens accepted: 64.44%\n",
      "Target: Die Polizei von Karratha beschuldigt einen 20-jährigen Mann der Nichtbeachtung eines Haltesignals sowie rücksichtslosen Fahrens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:04<01:32,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is due to appear in Karratha Magistrates Court on September 23.\n",
      "Normal Translation: Das GVL-Motorrad wird im Sommer für die Motorrad- und Bustouren in die bisherigen Schlachtfelder des Bundesstaates Tälambe in der Region in Betrieb nehmen.\n",
      "Time taken: 4.10 seconds\n",
      "Speculative Translation: Dieser wird am 23 September im Magistratgericht Karratha erscheinen\n",
      "Time taken: 0.72 seconds\n",
      "Percentage tokens accepted: 70.59%\n",
      "Target: Er soll am 23. September vor dem Amtsgericht in Karratha erscheinen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [01:06<01:13,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle was seized and impounded for three months.\n",
      "Normal Translation: Das Motorrad wurde beschlagnahmt und drei Monate beschlagnahmt.\n",
      "Time taken: 1.38 seconds\n",
      "Speculative Translation: Die Motorrad wurdeschlage und drei Monate langschlaget\n",
      "Time taken: 1.00 seconds\n",
      "Percentage tokens accepted: 36.00%\n",
      "Target: Das Motorrad wurde sichergestellt und für drei Monate beschlagnahmt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:10<01:06,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster accused of Nairn and Pitlochry hotel rapes\n",
      "Normal Translation: George Webster angeklagt, die Vergewaltigung von Gästen in Hotels in Nairn und Pitlochry begangen zu haben\n",
      "Time taken: 2.73 seconds\n",
      "Speculative Translation: George Webster hat der Vergewaltigung von Hotelgästen in Nair und Pitlochry beschuldigt\n",
      "Time taken: 1.04 seconds\n",
      "Percentage tokens accepted: 82.14%\n",
      "Target: George Webster wegen Hotelvergewaltigungen in Naim und Pitlochry angeklagt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:13<00:57,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A man is to stand trial accused of raping women at two hotels.\n",
      "Normal Translation: Ein Mann soll vor Gericht gestellt werden, weil er ihre Vergewaltigungen in zwei Hotels beschuldigt hat.\n",
      "Time taken: 2.28 seconds\n",
      "Speculative Translation: Ein Mann wird vor Gericht gestellt, weil er Frauen in zwei Hotels vergewaltigt hat.\n",
      "Time taken: 0.81 seconds\n",
      "Percentage tokens accepted: 100.00%\n",
      "Target: Ein Mann steht wegen der Vergewaltigung von Frauen in zwei Hotels vor Gericht.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:18<00:58,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster, 28, faced the charges during a hearing at the High Court in Glasgow.\n",
      "Normal Translation: A German blogger has accused a Belgian of committing a crime of slander. He reveals that he has signed up to support a campaign against slander.\n",
      "Time taken: 3.31 seconds\n",
      "Speculative Translation: Organische Platte hat sich in der südlichen Stadt ereignet. die südlichen Teile dieser Stadt sind südlich von Glasgow gelegen\n",
      "Time taken: 1.61 seconds\n",
      "Percentage tokens accepted: 78.05%\n",
      "Target: George Webster, 28, wurde die Anklage bei einer Anhörung von dem Obersten Gericht in Glasgow verlesen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [01:22<00:51,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is alleged to have raped a woman at the Scotland's Hotel in Pitlochry in Perthshire on June 7, 2013.\n",
      "Normal Translation: Er soll am 7. Juni 2013 eine Frau im Scotland’s Hotel in Pilton, Perthshire, vergewaltigt haben.\n",
      "Time taken: 2.35 seconds\n",
      "Speculative Translation: Er soll am 7. Juni 2013 eine Frau im Scottish's Hotel Pitlochry in Perthshire vergewaltig haben.\n",
      "Time taken: 1.16 seconds\n",
      "Percentage tokens accepted: 75.00%\n",
      "Target: Er wird beschuldigt, am 7. Juni 2013 eine Frau im Scotland's Hotel in Pitlochry in Perthshire vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [01:29<01:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: It is claimed Webster attacked her while she was \"unconscious, asleep and incapable of giving consent.\"\n",
      "Normal Translation: This is a portrait of a shocking and frightening episode in the history of the United States.\n",
      "Time taken: 1.72 seconds\n",
      "Speculative Translation: Der Name Webster  von Webster&#;seit demzweitenhebtrade,anders ernte er sich als '’unbewusst'', woken, und- waren nicht der Meinung, dass siediesen Dienstleisten erlauben würde. Wenn Webster wig hat, hat er eine ganze Reihe vongruppierten Dienst zu erledigen.\n",
      "Time taken: 5.81 seconds\n",
      "Percentage tokens accepted: 44.30%\n",
      "Target: Die Anklage lautet, dass Webster sie angriff, während sie \"bewusstlos war, schlief, und kein Einverständnis signalisieren konnte.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:34<00:54,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Webster is then charged with raping a second woman at the Golf View Hotel in Nairn in the Highlands on May 4, 2014.\n",
      "Normal Translation: Webster wird dann beschuldigt, am 4. Mai 2014 im Golf View Hotel in Nairn, Highlands, eine zweite Frau vergewaltigt zu haben.\n",
      "Time taken: 3.04 seconds\n",
      "Speculative Translation: Auf der anderen Seite wird Webster am 04. Mai 2014 mit Vergewaltigung einer zweiten Frau im Golf View Hotel in Nair in den Highland beaßt.\n",
      "Time taken: 1.71 seconds\n",
      "Percentage tokens accepted: 67.44%\n",
      "Target: Webster wird darüber hinaus vorgeworfen, am 4. Mai 2014 eine zweite Frau im Golf View Hotel in Naim im schottischen Hochland vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:39<00:49,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Judge Lady Rae set a trial date for November 17 at the High Court in Edinburgh.\n",
      "Normal Translation: Einem englischen Zeitung ist sogar zu entnehmen, dass die ffentlichkeit erwarb, dass die englische Regierung in Wahrheit ernsthaft verhaftet werden könne.\n",
      "Time taken: 3.66 seconds\n",
      "Speculative Translation: Die Richter Lady Ra beschloss, den 17. November vor dem US-Hochgericht in Edinburgh zu be.\n",
      "Time taken: 1.31 seconds\n",
      "Percentage tokens accepted: 53.12%\n",
      "Target: Richterin Lady Rae setzte den Verhandlungstermin für den 17. November am Obersten Gericht in Edinburgh an.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:41<00:38,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Reconnecting With the Very American Ideal That Labor Rights Are Human Rights\n",
      "Normal Translation: Eine Wiederherstellung des amerikanischen Ideals, dass Arbeitsrechte Menschenrechte sind\n",
      "Time taken: 1.61 seconds\n",
      "Speculative Translation: Ein neueswirken mit dem sehramerikanischen Ideal, dass Arbeitsrechte Menschenrechte sind\n",
      "Time taken: 0.99 seconds\n",
      "Percentage tokens accepted: 60.00%\n",
      "Target: Rückbesinnung auf das sehr amerikanische Ideal der Arbeitsrechte als Menschenrechte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:46<00:33,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Congressmen Keith Ellison and John Lewis have proposed legislation to protect union organizing as a civil right.\n",
      "Normal Translation: Die Kongressabgeordneten Keith Ellison und John Lewis haben Gesetzesvorschläge zur Schutz der Gewerkschaftsorganisation als Bürgerrecht vorgelegt.\n",
      "Time taken: 2.91 seconds\n",
      "Speculative Translation: Kongressabgeordnete Keith Ellison und John Lewis haben Gesetze vorgeschlagen, um Gewerkschaftsorganisationen Bürgerrechte zu schützen\n",
      "Time taken: 1.30 seconds\n",
      "Percentage tokens accepted: 76.47%\n",
      "Target: Die Kongressabgeordneten Keith Ellison und John Lewis haben einen Gesetzesvorschlag eingebracht, um die Organisation von Gewerkschaften als Bürgerrecht zu etablieren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:51<00:32,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: \"As go unions, so go middle-class jobs,\" says Ellison, the Minnesota Democrat who serves as a Congressional Progressive Caucus co-chair.\n",
      "Normal Translation: Und so geht es um die Mittelschichtarbeit, sagt Ellison, ein demokratischer Abgeordneter aus Minnesota, der im Kongress als Mitvorsitzender des Progressive Caucus dient.\n",
      "Time taken: 3.61 seconds\n",
      "Speculative Translation: \"So wie Gewerkschaften gehen, so auch die Arbeit Mittelklasse\", sagt Ellison, der Demokrat in Minnesota, der als Mitvorsitzender des Progressiven Kongressausschusse im Kongress fungiert\n",
      "Time taken: 2.13 seconds\n",
      "Percentage tokens accepted: 67.86%\n",
      "Target: \"So wie Gewerkschaften sterben, sterben auch die Mittelklassejobs,\" sagte Ellison, ein Demokrat aus Minnesota und stellvertretender Vorsitzender des Progressive Caucus im Kongress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:55<00:26,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: That's why I'm proud to introduce the Employee Empowerment Act with civil rights icon John Lewis.\n",
      "Normal Translation: Aus diesem Grund bin ich stolz, das Employee Empowerment Act mit dem Bürgerrechts-Ikonen John Lewis einzuführen.\n",
      "Time taken: 2.54 seconds\n",
      "Speculative Translation: Daher binich stolz, das Arbeitnehmereigenschaftsgesetz mit dem Bürgerrechtsikon Lewis einzuführen\n",
      "Time taken: 1.22 seconds\n",
      "Percentage tokens accepted: 58.06%\n",
      "Target: Daher stelle ich stolz gemeinsam mit der Bürgerrechtsikone John Lewis das Mitarbeiterermächtigungsgesetz vor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [02:02<00:25,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: This ground-breaking legislation will give workers the same legal options for union organizing discrimination as for other forms of discrimination - stopping anti-union forces in their tracks\n",
      "Normal Translation: Dieser wegweisende Rechtsakt wird den Arbeitnehmern dieselben Rechtsmöglichkeiten zur Diskriminierung aufgrund der Gewerkschaft organisierten Organisation wie für andere Diskriminierungen geben - was antigewerkschaftliche Kräfte aufhalten wird.\n",
      "Time taken: 4.63 seconds\n",
      "Speculative Translation: Dieser bahnbrechende Gesetzgeber wird den Arbeitnehmern die gleichen rechtlichen Möglichkeiten für die Organisation europäischer Diskriminierungen wie für Formen anderer Diskriminierung geben - die Gewerkschaftsfeindlichkeit in ihren Spuren zu stoppen\n",
      "Time taken: 2.33 seconds\n",
      "Percentage tokens accepted: 86.67%\n",
      "Target: Dieses bahnbrechende Gesetz gibt Arbeitern die gleichen rechtlichen Möglichkeiten bei Diskriminierung wegen der Organisation von Gewerkschaften wie bei anderen Formen der Diskriminierung - und stoppt so antigewerkschaftlich eingestellte Kräfte.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [02:13<00:27,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Amending the National Labor Relations Act to allow workers who face discrimination for engaging in union organizing to sue for justice in the civil courts - and to collect compensatory and punitive damages - is a sound and necessary initiative.\n",
      "Normal Translation: Die nderung des National Labor Relations Act, um Arbeitnehmern, die wegen ihrer Einbindung in eine Gewerkschaftsorganisierung diskriminiert worden sind, die Möglichkeit zu geben, gerichtlich gegen diese Diskriminierungen zu verklagen - und sowohl Entschädigungen als auch Strafschäden einzufordern -, ist eine tragfähige und notwendige Initiative.\n",
      "Time taken: 7.95 seconds\n",
      "Speculative Translation: Die nderung des Nationalen Arbeitsbeziehungsgesetze, um Arbeitnehmern, aufgrund der Gewerkschaftsorganisation diskriminiert werden, die Möglichkeit zu geben sich vor den Zivilgerichten um Gerechtigkeit zu klagen - und entschädigende punktuelle und kompens Schaden einzuziehen - eine gute und notwendige Initiative.\n",
      "Time taken: 3.23 seconds\n",
      "Percentage tokens accepted: 78.57%\n",
      "Target: Die Ergänzung des nationalen Arbeitsrechtsgesetzes, um eine Möglichkeit für einer Diskriminierung ausgesetzte Arbeitern zur Organisation einer Gewerkschaftsvertretung zu schaffen, um vor einem Zivilgericht um Gerechtigkeit zu klagen - und um Schadensersatz oder Strafgelder zu erhalten - ist eine sinnvolle und notwendige Initiative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [02:16<00:17,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: But it in certainly not a radical initiative - at least by American standards.\n",
      "Normal Translation: Aber es ist keine radikale Initiative - zumindest nach amerikanischen Standards.\n",
      "Time taken: 1.80 seconds\n",
      "Speculative Translation: Aber e ist sicherlich keineradikale Initiative - zumindest zum Beispiel nach amerikanischen.\n",
      "Time taken: 1.15 seconds\n",
      "Percentage tokens accepted: 62.07%\n",
      "Target: Aber es ist mit Sicherheit keine radikale Initiative - jedenfalls nicht nach amerikanischen Standards.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [02:22<00:11,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Indeed, the best way to understand what Ellison, Lewis and the cosponsors of their legislation are proposing is as a reconnection with a very American idea.\n",
      "Normal Translation: Tatsächlich lässt sich das, was Ellison, Lewis und die Mitentwickler ihrer Gesetze vorschlagen, am besten als eine Wiederherstellung einer sehr amerikanischen Idee verstehen.\n",
      "Time taken: 3.73 seconds\n",
      "Speculative Translation: Tatsächlich ist die beste Art, verstehen zu können was Ellison, Lewis und die Mitprofessoren ihrer Geetzgebung vorschlagen, eine Verknüpfung mit einer sehr amerikanischen Idee.30.\n",
      "Time taken: 2.22 seconds\n",
      "Percentage tokens accepted: 76.36%\n",
      "Target: Tatsächlich ist die beste Art und Weise zum Verständnis dessen, was Ellison, Lewis und die weiteren Sponsoren ihrer Gesetzesvorlage vorschlagen, die Verbindung zurück zu einer sehr amerikanischen Idee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [02:33<00:07,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Despite the battering that unions have taken in recent years - in Wisconsin, Michigan and states across the country - Americans once encouraged countries around the world to embrace, extend and respect labor rights.\n",
      "Normal Translation: Trotz der Schläge, die Gewerkschaften in den letzten Jahren - in Wisconsin, Michigan und in den Bundesstaaten - erlitten haben, haben die Amerikaner einst Länder weltweit ermutigt, die Arbeitnehmerrechte anzuerkennen, zu erweitern und zu respektieren.\n",
      "Time taken: 6.55 seconds\n",
      "Speculative Translation: Trotz der erschütternden Behandlungen die Gewerkschaften den letzten Jahren- in Wisconsin, Michigan und überall im Land - ermutigten die Amerikaner einst Länder auf der ganzen Welt, ihre Arbeitsrecht zu berücksichtig, auszuweiten zu respektieren sie zureden und zu reieren.\n",
      "Time taken: 3.90 seconds\n",
      "Percentage tokens accepted: 63.00%\n",
      "Target: Trotz der Rückschläge, denen die Gewerkschaften in den vergangenen Jahren ausgesetzt waren - in Wisconsin, Michigan und anderen Staaten im ganzen Land - haben Amerikaner einst Länder in aller Welt dazu ermutigt, Arbeitsrechte anzuerkennen, auszuweiten und einzuhalten.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:39<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: There was a time, within the living memory of millions of Americans, when this country championed democracy, freedom of speech, freedom of the press and the right to organize in the same breath.\n",
      "Normal Translation: Es gab eine Zeit, die Millionen von Amerikanern noch gut in Erinnerung hat, als dieses Land mit dem gleichen Atem Demokratie, Redefreiheit, Pressefreiheit und das Recht auf Organisation verteidigte.\n",
      "Time taken: 4.71 seconds\n",
      "Speculative Translation: Einer Zeit, in der Millionen von Amerikanern leben, war dieses Land für Demokrati, Redefreiheit, Pressefreiheit und das auf demselben Atemweg zu vertretende Recht.\n",
      "Time taken: 1.79 seconds\n",
      "Percentage tokens accepted: 84.44%\n",
      "Target: Es gab eine Zeit, an die sich Millionen von Amerikanern noch erinnern, als dieses Land Demokratie, Redefreiheit, Pressefreiheit und das Vereinigungsrecht in einem Atemzug nannte.\n",
      "\n",
      "Average time taken for normal decoding: 3.31 seconds\n",
      "Average time taken for speculative decoding: 2.01 seconds\n",
      "Average speedup over 30 iterations: 1.65x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize decoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "speculative_decoder = SpeculativeDecoder(gamma=7, temperature=1)\n",
    "normal_decoder = NormalDecoder()\n",
    "\n",
    "spec_total_time = 0\n",
    "normal_total_time = 0\n",
    "total_iters = 0\n",
    "\n",
    "for i in tqdm(en_gr_dataset['translation'][:30]):\n",
    "    source_text = i['en']\n",
    "    target_text = i['de']\n",
    "    \n",
    "    # Time the translation\n",
    "    start_time = time.time()\n",
    "    spec_translation, pc = speculative_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    spec_time = end_time - start_time\n",
    "\n",
    "    # spec_total_time += spec_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    normal_translation = normal_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    normal_time = end_time - start_time\n",
    "\n",
    "    # normal_total_time += normal_time\n",
    "\n",
    "    print(f\"Source: {source_text}\")\n",
    "    print(f\"Normal Translation: {normal_translation}\")\n",
    "    print(f\"Time taken: {normal_time:.2f} seconds\")\n",
    "    print(f\"Speculative Translation: {spec_translation}\")\n",
    "    print(f\"Time taken: {spec_time:.2f} seconds\")\n",
    "    print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "    \n",
    "    print(f\"Target: {target_text}\")\n",
    "\n",
    "    # if normal_time - spec_time > -0.1:\n",
    "    spec_total_time += spec_time\n",
    "    normal_total_time += normal_time\n",
    "    total_iters += 1\n",
    "\n",
    "print(f\"\\nAverage time taken for normal decoding: {normal_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average time taken for speculative decoding: {spec_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average speedup over {total_iters} iterations: {normal_total_time / spec_total_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "  3%|▎         | 1/30 [00:04<02:17,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India and Japan prime ministers meet in Tokyo\n",
      "Normal Translation: Indiens und Japans Ministerpräsidenten treffen sich in Tokio\n",
      "Time taken: 1.40 seconds\n",
      "Speculative Translation: Indien Japan und Ministerpräsident treffen in Toki\n",
      "Time taken: 3.33 seconds\n",
      "Percentage tokens accepted: 18.75%\n",
      "Target: Die Premierminister Indiens und Japans trafen sich in Tokio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:15<03:57,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\n",
      "Normal Translation: Der neue indische Ministerpräsident Narendra Modi trifft sich in Tokio mit seinem japanischen Amtskollegen Shinzo Abe, um wirtschaftliche und Sicherheitsbeziehungen zu erörtern, und zwar auf seinem ersten großen Auslandsbesuch seit dem Wahlsieg im Mai.\n",
      "Time taken: 6.22 seconds\n",
      "Speculative Translation: Der neuedines Premier Narendrai trifft japanse Premierminister Shi Abe Toki, um seinenersten großenbesuch seit Wahlsieg Mai inkio zu disktieren.\n",
      "Time taken: 4.86 seconds\n",
      "Percentage tokens accepted: 17.97%\n",
      "Target: Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:22<03:25,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.\n",
      "Normal Translation: Herr Modi ist auf einer fünftägigen Reise nach Japan, um die Wirtschaftsbeziehungen mit der drittgrößten Volkswirtschaft der Welt zu stärken.\n",
      "Time taken: 3.12 seconds\n",
      "Speculative Translation: Herr Mod ist auf fünftgige Besuche Japans um diewirtschaftlichenen Beziehung mit derdritt Volkswirtschaft Welt zustärken\n",
      "Time taken: 3.48 seconds\n",
      "Percentage tokens accepted: 15.05%\n",
      "Target: Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:25<02:31,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: High on the agenda are plans for greater nuclear co-operation.\n",
      "Normal Translation: Die Pläne für eine verstärkte nukleare Zusammenarbeit stehen ganz oben auf der Tagesordnung.\n",
      "Time taken: 1.66 seconds\n",
      "Speculative Translation: Auf derordnung stehenPläne für einee verstärkt nukle Zusammenarbeit.\n",
      "Time taken: 1.39 seconds\n",
      "Percentage tokens accepted: 20.00%\n",
      "Target: Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:30<02:21,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India is also reportedly hoping for a deal on defence collaboration between the two nations.\n",
      "Normal Translation: Der stärkste Verbündete der USA - die USA- sind mit Deutschland zusammen.\n",
      "Time taken: 2.20 seconds\n",
      "Speculative Translation: Indienhofftasasashofft  auf eine übergreifen Zusammenarbeit im der Vereidigung den beide Nationen.\n",
      "Time taken: 3.17 seconds\n",
      "Percentage tokens accepted: 17.44%\n",
      "Target: Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:35<02:08,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha police arrest 20-year-old after high speed motorcycle chase\n",
      "Normal Translation: Die Polizei in Karratha verhaftet aufgrund einer schnellen Radjagd einen 20-jährigen junger Mann\n",
      "Time taken: 2.26 seconds\n",
      "Speculative Translation: Karrat-Politikhaftes-Zitatammen-Fahr- undradjag\n",
      "Time taken: 2.57 seconds\n",
      "Percentage tokens accepted: 16.18%\n",
      "Target: Polizei von Karratha verhaftet 20-Jährigen nach schneller Motorradjagd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:48<02:58,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A motorcycle has been seized after it was ridden at 125km/h in a 70km/h zone and through bushland to escape police in the Pilbara.\n",
      "Normal Translation: Die australische Polizei hat eine Kutsche für über 100 Millionen US-Dollar in den USA beschlagnahmt. Sie wurde in Reinbesitz genommen, nachdem sie 125 km/h in einer 70 km/h Zone und durch Buschland gefahren hatte, um der Polizei in der Pilbara zu entkommen.\n",
      "Time taken: 6.96 seconds\n",
      "Speculative Translation: Ein Motor wurde benahmt nachdeme  mit km/ 125/h einer 70/kmh-one Zone durch Buslandrevierreit gefahren, um Polizei in Pilbar zu ent.\n",
      "Time taken: 5.75 seconds\n",
      "Percentage tokens accepted: 15.69%\n",
      "Target: Ein Motorrad wurde beschlagnahmt, nachdem der Fahrer es mit 125 km/h in einer 70 km/h-Zone und durch Buschland gefahren hatte, um der Polizei in Bilbara zu entkommen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:56<02:52,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Traffic police on patrol in Karratha this morning tried to pull over a blue motorcycle when they spotted it reaching 125km/h as it pulled out of a service station on Bathgate Road.\n",
      "Normal Translation: Die Verkehrspolizei in Karratha versuchte heute Morgen, ein blaues Motorrad zu stoppen, als es 125 km/h erreichte und die Tankstelle auf der Bathgate Road ausfährte.\n",
      "Time taken: 4.47 seconds\n",
      "Speculative Translation: Die Polizei Karratsa versuchte heutegen, 125/hFahrzeug zu über, als siee aus einerstation auf Bathgate heraus fuhr\n",
      "Time taken: 3.58 seconds\n",
      "Percentage tokens accepted: 18.95%\n",
      "Target: Verkehrspolizisten in Karratha versuchten heute morgen, ein blaues Motorrad zu stoppen, nachdem sie es dabei beobachtet hatten, wie es mit 125 km/h eine Tankstelle auf der Bathdate Road verließ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [01:06<03:01,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Police say the rider then failed to stop and continued on to Burgess Road before turning into bushland, causing the officers to lose sight of it.\n",
      "Normal Translation: Der Fahrer hat es nicht geschafft, zu stoppen und ging in die Burgess Road, bevor er sich in Buschwaden verwandelte, wodurch die Polizeikameraden ihn aus dem Blick verloren.\n",
      "Time taken: 4.52 seconds\n",
      "Speculative Translation: Die Polizei, diee die Fahrer an der Burgss fuhr,  hatgesagt, der Fahrer nicht angehalten bzw fuhr in dießstraße, bevorer sich Buschdrehenwandelt, wodurch Beamte aus Augen verlieren.\n",
      "Time taken: 5.87 seconds\n",
      "Percentage tokens accepted: 17.83%\n",
      "Target: Die Polizei berichtet, dass der Fahrer die Haltesignale dann ignorierte und weiter auf der Burgess Road fuhr, bevor er in das Buschland abbog, wo die Beamten es aus den Augen verloren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [01:12<02:33,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle and a person matching the description of the rider was then spotted at a house on Walcott Way in Bulgarra.\n",
      "Normal Translation: Das Motorrad und eine Person, die der Beschreibung des Fahrers entsprach, wurden dann an einem Haus am Walcott Way in Bulgarra gesehen.\n",
      "Time taken: 2.95 seconds\n",
      "Speculative Translation: Das Motor und eine Person die der des Fahrer entspricht, dann wurde einem Haus Walcott in Bularra gesehen\n",
      "Time taken: 2.51 seconds\n",
      "Percentage tokens accepted: 17.91%\n",
      "Target: Das Motorrad sowie eine Person, die der Beschreibung des Fahrers entsprach wurden später bei einem Haus im Walcott Way in Bulgarra gesehen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:18<02:16,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha Police have charged a 20-year-old man with failing to stop and reckless driving.\n",
      "Normal Translation: Die Polizei von Karratha hat einen 20-jährigen Mann wegen nicht eingehaltener Anweisungen und Fahrunwissens beschuldigt.\n",
      "Time taken: 2.73 seconds\n",
      "Speculative Translation: Die Polizei Karrat hat 20-rass Mann klagele sowohlfahrlässig auch nichtgehalten.\n",
      "Time taken: 3.39 seconds\n",
      "Percentage tokens accepted: 15.38%\n",
      "Target: Die Polizei von Karratha beschuldigt einen 20-jährigen Mann der Nichtbeachtung eines Haltesignals sowie rücksichtslosen Fahrens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:21<01:48,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is due to appear in Karratha Magistrates Court on September 23.\n",
      "Normal Translation: Er ist für am 23. September vor dem Karratha Magistrates Court anwesend zu erscheinen.\n",
      "Time taken: 1.93 seconds\n",
      "Speculative Translation: Er soll 23. vor demstrassen in Karha erscheinen\n",
      "Time taken: 1.44 seconds\n",
      "Percentage tokens accepted: 16.22%\n",
      "Target: Er soll am 23. September vor dem Amtsgericht in Karratha erscheinen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [01:24<01:25,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle was seized and impounded for three months.\n",
      "Normal Translation: Das Motorrad wurde beschlagnahmt und für drei Monate eingesperrt.\n",
      "Time taken: 1.50 seconds\n",
      "Speculative Translation: Das Motor wurde beschlagt und Monate langschlage.\n",
      "Time taken: 1.30 seconds\n",
      "Percentage tokens accepted: 22.58%\n",
      "Target: Das Motorrad wurde sichergestellt und für drei Monate beschlagnahmt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:28<01:16,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster accused of Nairn and Pitlochry hotel rapes\n",
      "Normal Translation: George Webster angeklagt für Hotelvergewaltigungen in Nairn und Pitlochry\n",
      "Time taken: 2.02 seconds\n",
      "Speculative Translation: George Web hat Vergewalungen inairn pitloch und airnschuldig gemacht\n",
      "Time taken: 2.14 seconds\n",
      "Percentage tokens accepted: 17.86%\n",
      "Target: George Webster wegen Hotelvergewaltigungen in Naim und Pitlochry angeklagt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:33<01:09,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A man is to stand trial accused of raping women at two hotels.\n",
      "Normal Translation: Ein Mann wird vor Gericht gestellt, weil er verdächtigt wird, Frauen in zwei Hotels vergewaltigt zu haben.\n",
      "Time taken: 2.54 seconds\n",
      "Speculative Translation: Ein Mann vor Gericht gestellt, der Frauen zweier vergewaltigte\n",
      "Time taken: 1.71 seconds\n",
      "Percentage tokens accepted: 20.00%\n",
      "Target: Ein Mann steht wegen der Vergewaltigung von Frauen in zwei Hotels vor Gericht.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:36<01:01,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster, 28, faced the charges during a hearing at the High Court in Glasgow.\n",
      "Normal Translation: Der 28-Jährige wurde bei einer Anhörung vor dem High Court in Glasgow beschuldigt.\n",
      "Time taken: 1.77 seconds\n",
      "Speculative Translation: George Web, 28,stellte sichwährend einerhörung High Court Glasgow den Anlagepunkt.\n",
      "Time taken: 2.12 seconds\n",
      "Percentage tokens accepted: 18.18%\n",
      "Target: George Webster, 28, wurde die Anklage bei einer Anhörung von dem Obersten Gericht in Glasgow verlesen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [01:41<00:58,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is alleged to have raped a woman at the Scotland's Hotel in Pitlochry in Perthshire on June 7, 2013.\n",
      "Normal Translation: Er soll am 7. Juni 2013 eine Frau im Scotland's Hotel in Pitlochry im Perthshire vergewaltigt haben.\n",
      "Time taken: 2.42 seconds\n",
      "Speculative Translation: Er soll 7. Juni eine Frau Scotland' Hotel inlochry Perthshiregefriert haben\n",
      "Time taken: 2.25 seconds\n",
      "Percentage tokens accepted: 16.67%\n",
      "Target: Er wird beschuldigt, am 7. Juni 2013 eine Frau im Scotland's Hotel in Pitlochry in Perthshire vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [01:49<01:05,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: It is claimed Webster attacked her while she was \"unconscious, asleep and incapable of giving consent.\"\n",
      "Normal Translation: Webster war in Boston unter der Regierung von Herbert Hoover tätig und arbeitete als Professor für Psychiatrie und Psychologie.\n",
      "Time taken: 2.99 seconds\n",
      "Speculative Translation: Websterhat die nicht wüende Frauangegriff auf ihre Körper richtet,während sieunbewusst schft nicht und in der ist, Zustimmung geben zu.\n",
      "Time taken: 4.72 seconds\n",
      "Percentage tokens accepted: 16.39%\n",
      "Target: Die Anklage lautet, dass Webster sie angriff, während sie \"bewusstlos war, schlief, und kein Einverständnis signalisieren konnte.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:56<01:04,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Webster is then charged with raping a second woman at the Golf View Hotel in Nairn in the Highlands on May 4, 2014.\n",
      "Normal Translation: Webster wird dann beschuldigt, eine zweite Frau im Golf View Hotel in Nairn in den Highlands am 4. Mai 2014.\n",
      "Time taken: 2.83 seconds\n",
      "Speculative Translation: Webster wird danachangeklag, eine Frau im View Hotel in Nnair in den Highland am 4. 2014 zugegriff zu verwalten\n",
      "Time taken: 4.13 seconds\n",
      "Percentage tokens accepted: 18.28%\n",
      "Target: Webster wird darüber hinaus vorgeworfen, am 4. Mai 2014 eine zweite Frau im Golf View Hotel in Naim im schottischen Hochland vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [02:01<00:57,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Judge Lady Rae set a trial date for November 17 at the High Court in Edinburgh.\n",
      "Normal Translation: Richterin Lady Rae hat den Prozesstermin für den 17. November 2006 auf das Hochverfassungsgericht Edinburgh verlegt.\n",
      "Time taken: 2.67 seconds\n",
      "Speculative Translation: Die Richter Lady Ra hat dem Ho Gericht in den letzten einen Termin den 17. Novembergegeben.\n",
      "Time taken: 2.58 seconds\n",
      "Percentage tokens accepted: 19.30%\n",
      "Target: Richterin Lady Rae setzte den Verhandlungstermin für den 17. November am Obersten Gericht in Edinburgh an.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [02:06<00:50,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Reconnecting With the Very American Ideal That Labor Rights Are Human Rights\n",
      "Normal Translation: Wiederherstellung der eigentümlich amerikanischen Idealstellung, dass Arbeitsrechte Menschenrechte sind\n",
      "Time taken: 2.45 seconds\n",
      "Speculative Translation: Wiederher des nüchtendens amerikanische Ideals dass Arbeitseigenen Menschenrecht sind\n",
      "Time taken: 2.79 seconds\n",
      "Percentage tokens accepted: 19.35%\n",
      "Target: Rückbesinnung auf das sehr amerikanische Ideal der Arbeitsrechte als Menschenrechte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [02:13<00:47,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Congressmen Keith Ellison and John Lewis have proposed legislation to protect union organizing as a civil right.\n",
      "Normal Translation: Die Kongressabgeordneten Keith Ellison und John Lewis haben Gesetzesvorschläge zum Schutz der Organisation von Gewerkschaften als Bürgerrecht unterbreitet.\n",
      "Time taken: 3.69 seconds\n",
      "Speculative Translation: Die Konamen Keithon und Lewis habensetzesschläge vor, umwerkliche Organisation als Bürgerrecht schützen zu können\n",
      "Time taken: 2.94 seconds\n",
      "Percentage tokens accepted: 22.73%\n",
      "Target: Die Kongressabgeordneten Keith Ellison und John Lewis haben einen Gesetzesvorschlag eingebracht, um die Organisation von Gewerkschaften als Bürgerrecht zu etablieren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [02:27<00:58,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: \"As go unions, so go middle-class jobs,\" says Ellison, the Minnesota Democrat who serves as a Congressional Progressive Caucus co-chair.\n",
      "Normal Translation: \"Was mit Gewerkschaften losgeht, geht auch mit den Arbeitsplätzen der Mittelschicht los\", meint Ellison, ein demokratischer Abgeordneter aus Minnesota, der als Ko-Vorsitzender des Kongresses-Fortschrittlichen Koalitionskaucus fungiert.\n",
      "Time taken: 7.34 seconds\n",
      "Speculative Translation: \"So die Geschaften, so Arbeitsplätze Mittelklasse sagt Ellis, der Demotär Minnesotas der alsvorsitzender Progressivergressi-Cucu des Konessusfungsses fung.\n",
      "Time taken: 6.75 seconds\n",
      "Percentage tokens accepted: 16.45%\n",
      "Target: \"So wie Gewerkschaften sterben, sterben auch die Mittelklassejobs,\" sagte Ellison, ein Demokrat aus Minnesota und stellvertretender Vorsitzender des Progressive Caucus im Kongress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [02:32<00:44,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: That's why I'm proud to introduce the Employee Empowerment Act with civil rights icon John Lewis.\n",
      "Normal Translation: Daher bin ich stolz darauf, das Employee Empowerment Act mit dem Bürgerrechtsikonen John Lewis einzuführen.\n",
      "Time taken: 2.79 seconds\n",
      "Speculative Translation: Deshalb binich stolz den Arbeitnehmerfähigkeitgesetz mit Bürgerrechtikon Lewis einzuführen\n",
      "Time taken: 2.36 seconds\n",
      "Percentage tokens accepted: 18.87%\n",
      "Target: Daher stelle ich stolz gemeinsam mit der Bürgerrechtsikone John Lewis das Mitarbeiterermächtigungsgesetz vor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [02:45<00:44,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: This ground-breaking legislation will give workers the same legal options for union organizing discrimination as for other forms of discrimination - stopping anti-union forces in their tracks\n",
      "Normal Translation: Diese bahnbrechende Gesetzgebung wird den Arbeitnehmern dieselben rechtlichen Möglichkeiten für Diskriminierung durch gewerkschaftliches Eingehen geben wie für andere Formen von Diskriminierung - und antigewerkschaftliche Kräfte vor der Keule stoppen.\n",
      "Time taken: 6.32 seconds\n",
      "Speculative Translation: Diese brechendes Geetz wird Arbeitnehmern gleicherechtliche Möglichkeiten Diskriierungsen fürwerksen bieten für andere Form von Disminierung- unddisminktion-Bempfängisse.\n",
      "Time taken: 6.23 seconds\n",
      "Percentage tokens accepted: 15.60%\n",
      "Target: Dieses bahnbrechende Gesetz gibt Arbeitern die gleichen rechtlichen Möglichkeiten bei Diskriminierung wegen der Organisation von Gewerkschaften wie bei anderen Formen der Diskriminierung - und stoppt so antigewerkschaftlich eingestellte Kräfte.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [03:01<00:44, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Amending the National Labor Relations Act to allow workers who face discrimination for engaging in union organizing to sue for justice in the civil courts - and to collect compensatory and punitive damages - is a sound and necessary initiative.\n",
      "Normal Translation: Die nderung des National Labor Relations Act, um Mitarbeitern, die Diskriminierungen wegen ihrer Aktivitäten aufgrund von Gewerkschaftsorganisationen zu beklagen haben, ein Rechtsmittel in Zivilsachen einzulegen - und Ersatz- und Strafschäden einzufordern - ist eine gesunde und notwendige Initiative.\n",
      "Time taken: 7.89 seconds\n",
      "Speculative Translation: Die nderung des Labor Relations, um Arbeitnehmer, dierimin werden,wegen ihre Gewerksorganisationriminen zurimmen die Möglichkeit geben, Zivile Gericht anzuk pfen- undschädigungs und Strafdenk zu langen, ist gute und notwendig Initiative.\n",
      "Time taken: 8.20 seconds\n",
      "Percentage tokens accepted: 16.39%\n",
      "Target: Die Ergänzung des nationalen Arbeitsrechtsgesetzes, um eine Möglichkeit für einer Diskriminierung ausgesetzte Arbeitern zur Organisation einer Gewerkschaftsvertretung zu schaffen, um vor einem Zivilgericht um Gerechtigkeit zu klagen - und um Schadensersatz oder Strafgelder zu erhalten - ist eine sinnvolle und notwendige Initiative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [03:08<00:29, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: But it in certainly not a radical initiative - at least by American standards.\n",
      "Normal Translation: Doch ist es zweifellos keine radikale Initiative - zumindest nicht nach amerikanischem Maßstab.\n",
      "Time taken: 2.67 seconds\n",
      "Speculative Translation: Aber sowohl innerhalb USA als auch Europas die größteffentlichkeithatt hat e nicht kaltföre Initiative erenk.\n",
      "Time taken: 4.78 seconds\n",
      "Percentage tokens accepted: 19.63%\n",
      "Target: Aber es ist mit Sicherheit keine radikale Initiative - jedenfalls nicht nach amerikanischen Standards.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [03:17<00:19,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Indeed, the best way to understand what Ellison, Lewis and the cosponsors of their legislation are proposing is as a reconnection with a very American idea.\n",
      "Normal Translation: In der Tat wird das, was Ellison, Lewis und die anderen Unterstützer ihrer Gesetze vorschlagen, am besten als Rückconnection zu einer sehr amerikanischen Idee verstanden.\n",
      "Time taken: 4.21 seconds\n",
      "Speculative Translation: Tatslich ist beste Verständnissweise was Ellis, Lewis die Verechterr ihre Gesetz vorschlagen als einekoppel mit einer sehramerikanischen Idee\n",
      "Time taken: 4.49 seconds\n",
      "Percentage tokens accepted: 17.65%\n",
      "Target: Tatsächlich ist die beste Art und Weise zum Verständnis dessen, was Ellison, Lewis und die weiteren Sponsoren ihrer Gesetzesvorlage vorschlagen, die Verbindung zurück zu einer sehr amerikanischen Idee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [03:34<00:11, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Despite the battering that unions have taken in recent years - in Wisconsin, Michigan and states across the country - Americans once encouraged countries around the world to embrace, extend and respect labor rights.\n",
      "Normal Translation: Trotz der Zerrüttung, die die Gewerkschaften in den letzten Jahren – in Wisconsin, Michigan und in allen Bundesstaaten – erlitten haben, ermutigten Amerikaner einst die Länder rund um die Welt, Arbeitsrechte zu begrüßen, auszubauen und zu respektieren.\n",
      "Time taken: 7.93 seconds\n",
      "Speculative Translation: Trotz der nüchtendeneinander reisierten Gewerkschaft in denletzten Jahren  in Wisconsin Michigan und allen Staat des Landeserbten mutierten Amerner eintä dazu, Länder der Welt daran teil, diee Recht der Arbeitnehmer akeptieren ausweit und zu achten\n",
      "Time taken: 9.16 seconds\n",
      "Percentage tokens accepted: 16.91%\n",
      "Target: Trotz der Rückschläge, denen die Gewerkschaften in den vergangenen Jahren ausgesetzt waren - in Wisconsin, Michigan und anderen Staaten im ganzen Land - haben Amerikaner einst Länder in aller Welt dazu ermutigt, Arbeitsrechte anzuerkennen, auszuweiten und einzuhalten.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:47<00:00,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: There was a time, within the living memory of millions of Americans, when this country championed democracy, freedom of speech, freedom of the press and the right to organize in the same breath.\n",
      "Normal Translation: Es gab eine Zeit, die noch im lebendigen Gedächtnis von Millionen von Amerikanern gelebt wird, als dieses Land in einem Atemzug für Demokratie, Redefreiheit, Pressefreiheit und das Recht auf Organisation eintrat.\n",
      "Time taken: 6.26 seconds\n",
      "Speculative Translation: Es gab Zeiten die in lebendige Gedächnis Millionen vonern Amernernreichen standen als diese Land Demoratie Rede, Pressfreiheit und Recht auf im gleich Atemzugverein vertte\n",
      "Time taken: 6.62 seconds\n",
      "Percentage tokens accepted: 17.33%\n",
      "Target: Es gab eine Zeit, an die sich Millionen von Amerikanern noch erinnern, als dieses Land Demokratie, Redefreiheit, Pressefreiheit und das Vereinigungsrecht in einem Atemzug nannte.\n",
      "\n",
      "Average time taken for normal decoding: 3.69 seconds\n",
      "Average time taken for speculative decoding: 3.89 seconds\n",
      "Average speedup over 30 iterations: 0.95x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize decoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "speculative_decoder = SpeculativeDecoder(gamma=7, temperature=0.0)\n",
    "normal_decoder = NormalDecoder()\n",
    "\n",
    "spec_total_time = 0\n",
    "normal_total_time = 0\n",
    "total_iters = 0\n",
    "\n",
    "for i in tqdm(en_gr_dataset['translation'][:30]):\n",
    "    source_text = i['en']\n",
    "    target_text = i['de']\n",
    "    \n",
    "    # Time the translation\n",
    "    start_time = time.time()\n",
    "    spec_translation, pc = speculative_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    spec_time = end_time - start_time\n",
    "\n",
    "    # spec_total_time += spec_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    normal_translation = normal_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    normal_time = end_time - start_time\n",
    "\n",
    "    # normal_total_time += normal_time\n",
    "\n",
    "    print(f\"Source: {source_text}\")\n",
    "    print(f\"Normal Translation: {normal_translation}\")\n",
    "    print(f\"Time taken: {normal_time:.2f} seconds\")\n",
    "    print(f\"Speculative Translation: {spec_translation}\")\n",
    "    print(f\"Time taken: {spec_time:.2f} seconds\")\n",
    "    print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "    \n",
    "    print(f\"Target: {target_text}\")\n",
    "\n",
    "    # if normal_time - spec_time > -0.1:\n",
    "    spec_total_time += spec_time\n",
    "    normal_total_time += normal_time\n",
    "    total_iters += 1\n",
    "\n",
    "print(f\"\\nAverage time taken for normal decoding: {normal_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average time taken for speculative decoding: {spec_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average speedup over {total_iters} iterations: {normal_total_time / spec_total_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "  3%|▎         | 1/30 [00:04<01:57,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India and Japan prime ministers meet in Tokyo\n",
      "Normal Translation: Indien und Japan unterhalten sich in Tokio\n",
      "Time taken: 1.17 seconds\n",
      "Speculative Translation: Indien und Japans Premierminister treffen sich Tokio\n",
      "Time taken: 2.88 seconds\n",
      "Percentage tokens accepted: 68.75%\n",
      "Target: Die Premierminister Indiens und Japans trafen sich in Tokio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:14<03:40,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\n",
      "Normal Translation: Der neue indische Premierminister Narendra Modi trifft sich heute mit seinem japanischen Kollegen Shinzo Abe in Tokio, um über wirtschaftliche und sicherheitspolitische Beziehungen zu sprechen. Dies ist sein erster größerer Auslandsbesuch seit dem Wahlsieg im Mai.\n",
      "Time taken: 6.67 seconds\n",
      "Speculative Translation: Der neuediente Ministerpräsident Narendra Mod trifft sein japanische Amtskollege Shinzo Abe in Tokio um über wirtschaftliche und Sicherheitsbeziehungen zu diskutieren,während erseinen erstenwichtigen Außenbesuch seit dem Sieg der Wahlen im Mai geführt hat\n",
      "Time taken: 3.91 seconds\n",
      "Percentage tokens accepted: 63.10%\n",
      "Target: Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:19<02:53,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.\n",
      "Normal Translation: Herr Modi ist auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen zur drittgrößten Volkswirtschaft der Welt zu verstärken.\n",
      "Time taken: 3.19 seconds\n",
      "Speculative Translation: Herr Mod ist auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen zur drittgrößten Volkswirtschaft der Welt zu stärken.\n",
      "Time taken: 1.48 seconds\n",
      "Percentage tokens accepted: 83.33%\n",
      "Target: Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:22<02:09,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: High on the agenda are plans for greater nuclear co-operation.\n",
      "Normal Translation: Die Pläne für eine verstärkte Zusammenarbeit im Bereich der Nuklearenergie stehen ganz oben auf der Tagesordnung.\n",
      "Time taken: 2.00 seconds\n",
      "Speculative Translation: Auf der Tagesordnung stehenPläne für eine verstärkt nukleare Zusammenarbeit.\n",
      "Time taken: 0.78 seconds\n",
      "Percentage tokens accepted: 63.16%\n",
      "Target: Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:25<01:47,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: India is also reportedly hoping for a deal on defence collaboration between the two nations.\n",
      "Normal Translation: Ebenso hofft Indien auf eine Vereinbarung über eine Zusammenarbeit in der Verteidigung.\n",
      "Time taken: 1.74 seconds\n",
      "Speculative Translation: In Indi sei ebenfalls auf eine Vereinbarung über die Zusammenarbeit im Verteidigungsbereich zwischen den beide Staaten hofft.\n",
      "Time taken: 1.31 seconds\n",
      "Percentage tokens accepted: 64.71%\n",
      "Target: Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:29<01:43,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha police arrest 20-year-old after high speed motorcycle chase\n",
      "Normal Translation: Bahnunternehmen setzt mit dem engl. Abegg-Flugzeugbau außerhalb der Zeitmessungseinrichtung in Bärnau um\n",
      "Time taken: 2.77 seconds\n",
      "Speculative Translation: Daspersonal der Polizei Karratha verhaftet 20 Jahre altes nach einemgeschwindigkeitsstarken Motorradjagd\n",
      "Time taken: 1.57 seconds\n",
      "Percentage tokens accepted: 42.86%\n",
      "Target: Polizei von Karratha verhaftet 20-Jährigen nach schneller Motorradjagd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:37<02:05,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A motorcycle has been seized after it was ridden at 125km/h in a 70km/h zone and through bushland to escape police in the Pilbara.\n",
      "Normal Translation: Die deutsche Gesellschaft für Landschaftspflege hat die grüne Wirtschaftskrise schließlich besiegt. Das Unternehmen stellt sich zum Beispiel auf das Pflanzen von Pflaumen ein.\n",
      "Time taken: 3.79 seconds\n",
      "Speculative Translation: Over the course of weekend, Turin was a great place to be. Theremained of the aforementioned-- night-timegaps.The aforementioned-- many of players are nowen a...tly - a s cyclist\n",
      "Time taken: 4.08 seconds\n",
      "Percentage tokens accepted: 42.57%\n",
      "Target: Ein Motorrad wurde beschlagnahmt, nachdem der Fahrer es mit 125 km/h in einer 70 km/h-Zone und durch Buschland gefahren hatte, um der Polizei in Bilbara zu entkommen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:43<02:02,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Traffic police on patrol in Karratha this morning tried to pull over a blue motorcycle when they spotted it reaching 125km/h as it pulled out of a service station on Bathgate Road.\n",
      "Normal Translation: Die Traffic Police, die heute morgen ein paar Autos auf der Business Park Road abworben, versuchten, ein blaues Motorrad zu stoppen, als sie es auf 125 km/h fuhr.\n",
      "Time taken: 4.54 seconds\n",
      "Speculative Translation: Der deutsche Bundes Bademeister hat sich in der Damen- und HerrenGruppe für die deutsche Bundeswehr eingesetzt.\n",
      "Time taken: 1.22 seconds\n",
      "Percentage tokens accepted: 72.41%\n",
      "Target: Verkehrspolizisten in Karratha versuchten heute morgen, ein blaues Motorrad zu stoppen, nachdem sie es dabei beobachtet hatten, wie es mit 125 km/h eine Tankstelle auf der Bathdate Road verließ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:48<01:53,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Police say the rider then failed to stop and continued on to Burgess Road before turning into bushland, causing the officers to lose sight of it.\n",
      "Normal Translation: Das Unternehmen ist im Handel mit einer Vielzahl von Produkten aktiv geworden, die es an die Wirtschaftskrise angepasst haben.\n",
      "Time taken: 2.51 seconds\n",
      "Speculative Translation: Der Fahrerhat dann nicht angehalten undfuhr weiter die Burgess Road, bevor er in einem Buschlande wechsele, wodurch die Offiziere e aus den Augen verloren\n",
      "Time taken: 2.58 seconds\n",
      "Percentage tokens accepted: 47.06%\n",
      "Target: Die Polizei berichtet, dass der Fahrer die Haltesignale dann ignorierte und weiter auf der Burgess Road fuhr, bevor er in das Buschland abbog, wo die Beamten es aus den Augen verloren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:52<01:43,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle and a person matching the description of the rider was then spotted at a house on Walcott Way in Bulgarra.\n",
      "Normal Translation: Am Samstag, dem ersten Tag der Konferenz, wurde der Präsident von der örtlichen Polizistin, Ms.\n",
      "Time taken: 2.57 seconds\n",
      "Speculative Translation: Das Motorrad und eine Person, die der Beschreibung desser ähnet, wurden dann in einem Haus auf der Walcott Way ing.H\n",
      "Time taken: 2.05 seconds\n",
      "Percentage tokens accepted: 50.00%\n",
      "Target: Das Motorrad sowie eine Person, die der Beschreibung des Fahrers entsprach wurden später bei einem Haus im Walcott Way in Bulgarra gesehen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:03<02:07,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Karratha Police have charged a 20-year-old man with failing to stop and reckless driving.\n",
      "Normal Translation: Der amerikanische Filmgoon Havok ist für die ganze Welt bekannt geworden.\n",
      "Time taken: 1.60 seconds\n",
      "Speculative Translation: If you are a teen, turn up the and learning to bead a little bit more. Then you can get a little  little more information about the upcoming upcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcomingupcoming upcoming\n",
      "Time taken: 8.67 seconds\n",
      "Percentage tokens accepted: 34.96%\n",
      "Target: Die Polizei von Karratha beschuldigt einen 20-jährigen Mann der Nichtbeachtung eines Haltesignals sowie rücksichtslosen Fahrens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:05<01:35,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is due to appear in Karratha Magistrates Court on September 23.\n",
      "Normal Translation: Er soll am 23. September vor dem Amtshof Karratha erscheinen.\n",
      "Time taken: 1.49 seconds\n",
      "Speculative Translation: Er soll am 23. September im Magistratgericht Karratha erscheinen.\n",
      "Time taken: 0.59 seconds\n",
      "Percentage tokens accepted: 100.00%\n",
      "Target: Er soll am 23. September vor dem Amtsgericht in Karratha erscheinen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [01:07<01:14,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: The motorcycle was seized and impounded for three months.\n",
      "Normal Translation: Das Motorrad wurde beschlagnahmt und für drei Monate beschlagnahmt.\n",
      "Time taken: 1.48 seconds\n",
      "Speculative Translation: Der Motorrad wurde beschlagnahm und drei Monate lang beschlagnahm.\n",
      "Time taken: 0.69 seconds\n",
      "Percentage tokens accepted: 86.67%\n",
      "Target: Das Motorrad wurde sichergestellt und für drei Monate beschlagnahmt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:10<01:04,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster accused of Nairn and Pitlochry hotel rapes\n",
      "Normal Translation: George Webster angeklagt für die Vergewaltigungen in Hotels in Nairn und Pitlochry\n",
      "Time taken: 2.18 seconds\n",
      "Speculative Translation: George Webster hat der Vergewaltigung von Hotelgästen in Nair und Pitlochry beschuldigt\n",
      "Time taken: 1.08 seconds\n",
      "Percentage tokens accepted: 82.14%\n",
      "Target: George Webster wegen Hotelvergewaltigungen in Naim und Pitlochry angeklagt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:13<00:56,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A man is to stand trial accused of raping women at two hotels.\n",
      "Normal Translation: Ein Mann steht vor Verhandlung, weil er beschuldigt wurde, Frauen in zwei Hotels vergewaltigt zu haben.\n",
      "Time taken: 2.35 seconds\n",
      "Speculative Translation: Der Mann wird vor Gericht gestellt, weil er Frauen in zwei Hotels vergewaltigt hat.\n",
      "Time taken: 0.82 seconds\n",
      "Percentage tokens accepted: 100.00%\n",
      "Target: Ein Mann steht wegen der Vergewaltigung von Frauen in zwei Hotels vor Gericht.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:17<00:50,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: George Webster, 28, faced the charges during a hearing at the High Court in Glasgow.\n",
      "Normal Translation: Der 28-Jährige setzte sich bei einer Anhörung des High Court in Glasgow vor den Anklagepunkt.\n",
      "Time taken: 2.18 seconds\n",
      "Speculative Translation: Einer Anhörung des Hohen Gerichts in Glasgow stand George Webster, 28 Jahre alt, vor entsprechenden Anklagen.\n",
      "Time taken: 1.05 seconds\n",
      "Percentage tokens accepted: 88.89%\n",
      "Target: George Webster, 28, wurde die Anklage bei einer Anhörung von dem Obersten Gericht in Glasgow verlesen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [01:21<00:50,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: He is alleged to have raped a woman at the Scotland's Hotel in Pitlochry in Perthshire on June 7, 2013.\n",
      "Normal Translation: Er wird beschuldigt, am 7. Juni 2013 eine Frau im Scotland's Hotel in Pitlochry in Perthshire vergewaltigt zu haben.\n",
      "Time taken: 2.84 seconds\n",
      "Speculative Translation: Außerdem hater eine Frau Scotland' Hotel in Pitlochry Perthshire am 7. Juni 2013 vergewaltig.\n",
      "Time taken: 1.63 seconds\n",
      "Percentage tokens accepted: 47.50%\n",
      "Target: Er wird beschuldigt, am 7. Juni 2013 eine Frau im Scotland's Hotel in Pitlochry in Perthshire vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [01:23<00:38,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: It is claimed Webster attacked her while she was \"unconscious, asleep and incapable of giving consent.\"\n",
      "Normal Translation: Die ersten Angaben sind nur eine Quelle.\n",
      "Time taken: 0.92 seconds\n",
      "Speculative Translation: Der Name Webster  aus dem Jahr 1887stammt aus dem Jahr 1887\n",
      "Time taken: 0.83 seconds\n",
      "Percentage tokens accepted: 61.90%\n",
      "Target: Die Anklage lautet, dass Webster sie angriff, während sie \"bewusstlos war, schlief, und kein Einverständnis signalisieren konnte.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:28<00:41,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Webster is then charged with raping a second woman at the Golf View Hotel in Nairn in the Highlands on May 4, 2014.\n",
      "Normal Translation: Webster wird dann angeklagt, eine zweite Frau am 4. Mai 2014 im Golf View Hotel in Nairn in den Highlands vergewaltigt zu haben.\n",
      "Time taken: 3.28 seconds\n",
      "Speculative Translation: Webster wird dann am 4. Mai 2014 des Verwalten einer zweiten Frau im Golf View Hotel in Nair im Highlands angeklagt.\n",
      "Time taken: 1.71 seconds\n",
      "Percentage tokens accepted: 60.47%\n",
      "Target: Webster wird darüber hinaus vorgeworfen, am 4. Mai 2014 eine zweite Frau im Golf View Hotel in Naim im schottischen Hochland vergewaltigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:31<00:36,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Judge Lady Rae set a trial date for November 17 at the High Court in Edinburgh.\n",
      "Normal Translation: Die Gerichtsverhandlung im Edinburgher Oberster Gerichtshof wurde gegen die drei Männer für den 17. November angesetzt.\n",
      "Time taken: 2.18 seconds\n",
      "Speculative Translation: Die Richter Lady Ra hat vor dem Hohen Gericht in Edinburgh ein Verfahrensdatum den 17. November festgelegt\n",
      "Time taken: 1.27 seconds\n",
      "Percentage tokens accepted: 54.55%\n",
      "Target: Richterin Lady Rae setzte den Verhandlungstermin für den 17. November am Obersten Gericht in Edinburgh an.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:34<00:30,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Reconnecting With the Very American Ideal That Labor Rights Are Human Rights\n",
      "Normal Translation: Wiederzustoßen mit dem sehr amerikanischen Ideal, dass die Arbeitsrechte Menschenrechte sind\n",
      "Time taken: 1.83 seconds\n",
      "Speculative Translation: Wiederherstellung der zum amerikanische Ideal gehörenden Arbeitsrecht als Menschenrechte\n",
      "Time taken: 0.97 seconds\n",
      "Percentage tokens accepted: 54.17%\n",
      "Target: Rückbesinnung auf das sehr amerikanische Ideal der Arbeitsrechte als Menschenrechte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:38<00:29,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Congressmen Keith Ellison and John Lewis have proposed legislation to protect union organizing as a civil right.\n",
      "Normal Translation: Die Kongressabgeordneten Keith Ellison und John Lewis haben Gesetzesvorschläge für den Schutz des Gewerkschaftsrechts vorgelegt.\n",
      "Time taken: 2.89 seconds\n",
      "Speculative Translation: Die Kongressabgeordneten Keith Ellison und John Lewis haben Gesetze vorgeschlagen um Gewerkschaftbildung als Bürgerrecht schützen zu können\n",
      "Time taken: 1.51 seconds\n",
      "Percentage tokens accepted: 61.54%\n",
      "Target: Die Kongressabgeordneten Keith Ellison und John Lewis haben einen Gesetzesvorschlag eingebracht, um die Organisation von Gewerkschaften als Bürgerrecht zu etablieren.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:44<00:30,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: \"As go unions, so go middle-class jobs,\" says Ellison, the Minnesota Democrat who serves as a Congressional Progressive Caucus co-chair.\n",
      "Normal Translation: \"Wenn die Gewerkschaften gehen, gehen die Arbeitsplätze der Mittelschicht\" sagt Ellison, der demokratische Mitglied aus Minnesota und Mitvorsitzender des Progressive Caucus im Kongress.\n",
      "Time taken: 3.97 seconds\n",
      "Speculative Translation: \"So wie Gewerkschaften gehen, so Arbeitsplätze der Mittelschicht\", sagt Ellison, der Demokrat in Minnesota, der als Mitvorsitzender des Progressiven Kongresse dient.\n",
      "Time taken: 1.78 seconds\n",
      "Percentage tokens accepted: 77.27%\n",
      "Target: \"So wie Gewerkschaften sterben, sterben auch die Mittelklassejobs,\" sagte Ellison, ein Demokrat aus Minnesota und stellvertretender Vorsitzender des Progressive Caucus im Kongress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:48<00:25,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: That's why I'm proud to introduce the Employee Empowerment Act with civil rights icon John Lewis.\n",
      "Normal Translation: Deshalb bin ich stolz, den Employee Empowerment Act mit dem Gehorsamsiker der Bürgerrechte John Lewis einzuführen.\n",
      "Time taken: 2.64 seconds\n",
      "Speculative Translation: Aus diesem Grund binich stolz, das Arbeitnehmereigenschaftsgesetz mit dem Bürgerrechtsikon John Lewisführen zu lassen\n",
      "Time taken: 1.27 seconds\n",
      "Percentage tokens accepted: 70.97%\n",
      "Target: Daher stelle ich stolz gemeinsam mit der Bürgerrechtsikone John Lewis das Mitarbeiterermächtigungsgesetz vor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [01:56<00:26,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: This ground-breaking legislation will give workers the same legal options for union organizing discrimination as for other forms of discrimination - stopping anti-union forces in their tracks\n",
      "Normal Translation: Diese bahnbrechende Gesetzgebung wird den Arbeitnehmern dieselben Rechtsoptionen zur Diskriminierung wegen Gewerkschaftsorganisation wie für andere Formen von Diskriminierung bieten und antigewerkschaftliche Kräfte aufhalten\n",
      "Time taken: 4.50 seconds\n",
      "Speculative Translation: Diese bahnbrechendes Gesetz wird den Arbeitnehmern das gleicherechtliche Recht geben, wenn e um die Organisation vonkriminellen Diskriierungen geht, bei anderenen Form der Diskriminierung - die antigewerkschaftlichen Kräfte in ihren Spuren zu stoppen\n",
      "Time taken: 3.19 seconds\n",
      "Percentage tokens accepted: 59.52%\n",
      "Target: Dieses bahnbrechende Gesetz gibt Arbeitern die gleichen rechtlichen Möglichkeiten bei Diskriminierung wegen der Organisation von Gewerkschaften wie bei anderen Formen der Diskriminierung - und stoppt so antigewerkschaftlich eingestellte Kräfte.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [02:06<00:27,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Amending the National Labor Relations Act to allow workers who face discrimination for engaging in union organizing to sue for justice in the civil courts - and to collect compensatory and punitive damages - is a sound and necessary initiative.\n",
      "Normal Translation: Die nderung des National Labor Relations Act, die es Arbeitnehmern, die aufgrund ihrer Gewerkschaftsbeteiligung diskriminiert werden, erlaubt, vor Zivilgerichten zu klagen und Schadensersatz- und Strafschäden zu fordern, ist eine vernünftige und notwendige Initiative.\n",
      "Time taken: 6.97 seconds\n",
      "Speculative Translation: Die nderung des Nationalen Arbeitsbeziehungsgesetze, um Arbeitnehmern, zur Diskriminierung wegen Gewerkschaftsorganisationen zu werden, die Möglichkeit zu geben, vor den Zivilgericht für Gerechtigkeit zu klagen - und Entschädigungs- Strafschädigung einzulegen  ist eine gute und notwendig Initiative.\n",
      "Time taken: 3.69 seconds\n",
      "Percentage tokens accepted: 61.29%\n",
      "Target: Die Ergänzung des nationalen Arbeitsrechtsgesetzes, um eine Möglichkeit für einer Diskriminierung ausgesetzte Arbeitern zur Organisation einer Gewerkschaftsvertretung zu schaffen, um vor einem Zivilgericht um Gerechtigkeit zu klagen - und um Schadensersatz oder Strafgelder zu erhalten - ist eine sinnvolle und notwendige Initiative.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [02:10<00:17,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: But it in certainly not a radical initiative - at least by American standards.\n",
      "Normal Translation: Aber sicherlich ist sie keine radikale Initiative - zumindest nicht nach amerikanischen Standards.\n",
      "Time taken: 1.93 seconds\n",
      "Speculative Translation: Doch e ist sicherlich radikal - zumindest nach amerikanische Maßstäb.\n",
      "Time taken: 1.43 seconds\n",
      "Percentage tokens accepted: 47.22%\n",
      "Target: Aber es ist mit Sicherheit keine radikale Initiative - jedenfalls nicht nach amerikanischen Standards.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [02:16<00:11,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Indeed, the best way to understand what Ellison, Lewis and the cosponsors of their legislation are proposing is as a reconnection with a very American idea.\n",
      "Normal Translation: Tatsächlich verstehen wir das, was Ellison, Lewis und die Mitbegründer ihres Gesetzesentwurfs vorschlagen, am besten als eine Wiederherstellung einer sehr amerikanischen Idee.\n",
      "Time taken: 3.97 seconds\n",
      "Speculative Translation: Tatsächlich ist die beste Art, verstehen zu können was Ellison, Lewis und die Mitsponoren ihrer Gesetzgebung vorschlagen, eine Verknüpfung mit einer sehr amerikanischen Idee.\n",
      "Time taken: 2.30 seconds\n",
      "Percentage tokens accepted: 68.97%\n",
      "Target: Tatsächlich ist die beste Art und Weise zum Verständnis dessen, was Ellison, Lewis und die weiteren Sponsoren ihrer Gesetzesvorlage vorschlagen, die Verbindung zurück zu einer sehr amerikanischen Idee.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [02:26<00:07,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Despite the battering that unions have taken in recent years - in Wisconsin, Michigan and states across the country - Americans once encouraged countries around the world to embrace, extend and respect labor rights.\n",
      "Normal Translation: Trotz der Schläge, die die Gewerkschaften in den letzten Jahren - in Wisconsin, Michigan und anderen Bundesstaaten - erlitten haben, ermutigten Amerikaner einst Länder auf der ganzen Welt, ihre Arbeitsrechte zu übernehmen, auszubauen und zu achten.\n",
      "Time taken: 6.27 seconds\n",
      "Speculative Translation: Trotz der erschütternden Lesezeiten, die die Gewerkschaften in den letzten Jahren - in Wisconsin, Michigan und überall im Land  - ergriffen haben, ermutigten die Amikaner einst Länder auf der ganzen Welt, ihre Arbeitsrechte zu berücksichtig, auszuweit und zu respektieren\n",
      "Time taken: 3.27 seconds\n",
      "Percentage tokens accepted: 79.76%\n",
      "Target: Trotz der Rückschläge, denen die Gewerkschaften in den vergangenen Jahren ausgesetzt waren - in Wisconsin, Michigan und anderen Staaten im ganzen Land - haben Amerikaner einst Länder in aller Welt dazu ermutigt, Arbeitsrechte anzuerkennen, auszuweiten und einzuhalten.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:33<00:00,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: There was a time, within the living memory of millions of Americans, when this country championed democracy, freedom of speech, freedom of the press and the right to organize in the same breath.\n",
      "Normal Translation: Es gab eine Zeit, die Millionen von Amerikanern noch gut im Gedächtnis hat, als dieses Land Demokratie, Redefreiheit, Pressefreiheit und das Recht auf Organisationsfreiheit in einem Atemzug verteidigte.\n",
      "Time taken: 5.39 seconds\n",
      "Speculative Translation: Es gab eine Zeit, in der Millionen von Amerikanern leben, als dieses Land Demokrati, Redfreiheit, Pressfreiheit und das Recht, sich in gleicher Weise zu organisieren, für sich einsetzt.\n",
      "Time taken: 2.25 seconds\n",
      "Percentage tokens accepted: 72.22%\n",
      "Target: Es gab eine Zeit, an die sich Millionen von Amerikanern noch erinnern, als dieses Land Demokratie, Redefreiheit, Pressefreiheit und das Vereinigungsrecht in einem Atemzug nannte.\n",
      "\n",
      "Average time taken for normal decoding: 3.06 seconds\n",
      "Average time taken for speculative decoding: 2.06 seconds\n",
      "Average speedup over 30 iterations: 1.48x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize decoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "speculative_decoder = SpeculativeDecoder(gamma=7, temperature=0.8)\n",
    "normal_decoder = NormalDecoder()\n",
    "\n",
    "spec_total_time = 0\n",
    "normal_total_time = 0\n",
    "total_iters = 0\n",
    "\n",
    "for i in tqdm(en_gr_dataset['translation'][:30]):\n",
    "    source_text = i['en']\n",
    "    target_text = i['de']\n",
    "    \n",
    "    # Time the translation\n",
    "    start_time = time.time()\n",
    "    spec_translation, pc = speculative_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    spec_time = end_time - start_time\n",
    "\n",
    "    # spec_total_time += spec_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    normal_translation = normal_decoder.translate(source_text)\n",
    "    end_time = time.time()\n",
    "\n",
    "    normal_time = end_time - start_time\n",
    "\n",
    "    # normal_total_time += normal_time\n",
    "\n",
    "    print(f\"Source: {source_text}\")\n",
    "    print(f\"Normal Translation: {normal_translation}\")\n",
    "    print(f\"Time taken: {normal_time:.2f} seconds\")\n",
    "    print(f\"Speculative Translation: {spec_translation}\")\n",
    "    print(f\"Time taken: {spec_time:.2f} seconds\")\n",
    "    print(f\"Percentage tokens accepted: {pc:.2f}%\")\n",
    "    \n",
    "    print(f\"Target: {target_text}\")\n",
    "\n",
    "    # if normal_time - spec_time > -0.1:\n",
    "    spec_total_time += spec_time\n",
    "    normal_total_time += normal_time\n",
    "    total_iters += 1\n",
    "\n",
    "print(f\"\\nAverage time taken for normal decoding: {normal_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average time taken for speculative decoding: {spec_total_time / total_iters:.2f} seconds\")\n",
    "print(f\"Average speedup over {total_iters} iterations: {normal_total_time / spec_total_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineSpeculativeDecoder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_model_name = \"google-t5/t5-large\",\n",
    "        draft_model_name = \"google-t5/t5-small\",\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        gamma = 4,\n",
    "        update_interval=2,  # Update draft model after every `update_interval` iterations\n",
    "        buffer_size_threshold=2,  # Buffer size threshold for updates\n",
    "        time_threshold=2,  # Time threshold (in seconds) for updates\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.gamma = gamma\n",
    "        self.update_interval = update_interval\n",
    "        self.buffer_size_threshold = buffer_size_threshold\n",
    "        self.time_threshold = time_threshold\n",
    "        self.last_update_time = time.time()  # Track last update time\n",
    "\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(target_model_name)\n",
    "        self.target_model = T5ForConditionalGeneration.from_pretrained(target_model_name).to(device)\n",
    "        self.draft_model = T5ForConditionalGeneration.from_pretrained(draft_model_name).to(device)\n",
    "\n",
    "        self.target_model.eval()\n",
    "        self.draft_model.eval()\n",
    "\n",
    "        # Buffers for storing token proposals and updates\n",
    "        self.replay_buffer = []\n",
    "        self.temp_buffer = []  # Temporary buffer for a single request\n",
    "\n",
    "        # Counter for iteration tracking\n",
    "        self.iteration_count = 0\n",
    "\n",
    "    def get_draft_logits(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        decoder_input_ids: torch.Tensor,\n",
    "        gamma: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Get draft logits for gamma tokens\"\"\"\n",
    "        draft_tokens = []\n",
    "        draft_probs = []\n",
    "        current_decoder_ids = decoder_input_ids\n",
    "\n",
    "        # Generate gamma tokens from the draft model\n",
    "        for _ in range(gamma):\n",
    "            with torch.no_grad():\n",
    "                outputs = self.draft_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    decoder_input_ids=current_decoder_ids,\n",
    "                    return_dict=True\n",
    "                )\n",
    "                logits = outputs.logits[:, -1, :]  # Get logits for last position\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                # Sample token\n",
    "                token_id = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "                prob = probs.gather(-1, token_id.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "                draft_tokens.append(token_id.item())\n",
    "                draft_probs.append(prob.item())\n",
    "\n",
    "                # Update decoder inputs for next iteration\n",
    "                current_decoder_ids = torch.cat(\n",
    "                    [current_decoder_ids, token_id.view(1, 1)],\n",
    "                    dim=1\n",
    "                )\n",
    "\n",
    "                if token_id.item() == self.tokenizer.eos_token_id:\n",
    "                    break\n",
    "\n",
    "        return draft_tokens, draft_probs, current_decoder_ids, outputs.logits\n",
    "\n",
    "    def get_target_probs(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        decoder_input_ids: torch.Tensor,\n",
    "        draft_tokens: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Get target probabilities for the draft tokens in parallel.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Add draft tokens to decoder input\n",
    "            full_decoder_ids = torch.cat([decoder_input_ids, draft_tokens.unsqueeze(0)], dim=1)\n",
    "\n",
    "            outputs = self.target_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                decoder_input_ids=full_decoder_ids,\n",
    "                return_dict=True\n",
    "            )\n",
    "\n",
    "            # Get probabilities for positions before each draft token\n",
    "            logits = outputs.logits[:, -(len(draft_tokens) + 1):-1, :]\n",
    "            target_probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            return target_probs.squeeze(0), outputs.logits\n",
    "        \n",
    "    def get_logits(self, model, input_ids, attention_mask):\n",
    "        return model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        ).logits\n",
    "\n",
    "    def verify_tokens(\n",
    "        self,\n",
    "        target_probs: torch.Tensor,\n",
    "        draft_tokens: torch.Tensor,\n",
    "        draft_probs: torch.Tensor,\n",
    "    ) -> int:\n",
    "        \"\"\"Determine number of accepted tokens\"\"\"\n",
    "        # Get target probabilities for the draft tokens\n",
    "        target_probs_draft_tokens = target_probs.gather(\n",
    "            -1,\n",
    "            draft_tokens.unsqueeze(-1)\n",
    "        ).squeeze(-1)\n",
    "\n",
    "        # Calculate acceptance ratios\n",
    "        acceptance_ratios = target_probs_draft_tokens / draft_probs\n",
    "\n",
    "        # Sample uniform random numbers\n",
    "        random_nums = torch.rand_like(acceptance_ratios)\n",
    "\n",
    "        # Find number of accepted tokens\n",
    "        # Accept if random number < min(1, target_prob / draft_prob)\n",
    "        accepts = random_nums < torch.minimum(\n",
    "            torch.ones_like(acceptance_ratios),\n",
    "            acceptance_ratios\n",
    "        )\n",
    "\n",
    "        # Find first rejection\n",
    "        try:\n",
    "            n_accepted = torch.where(~accepts)[0][0].item()\n",
    "        except:\n",
    "            n_accepted = len(accepts)\n",
    "\n",
    "        return n_accepted\n",
    "\n",
    "        # accepted_tokens = []\n",
    "        # for i in range(len(draft_tokens)):\n",
    "        #     if target_probs[i] / draft_probs[i] > torch.rand(1).item():\n",
    "        #         accepted_tokens.append(draft_tokens[i])\n",
    "        #     else:\n",
    "        #         break # Stop if token is not accepted\n",
    "\n",
    "        # return len(accepted_tokens)\n",
    "    \n",
    "    # TODO: verify this, might need to do some window size thing\n",
    "    def update_draft_model(self):\n",
    "        \"\"\"Update draft model with the replay buffer.\"\"\"\n",
    "        if len(self.replay_buffer) == 0:\n",
    "            return\n",
    "\n",
    "        # Get draft tokens, draft and target probabilities from the replay buffer\n",
    "        # draft_tokens = torch.tensor([x[0] for x in self.replay_buffer], device=self.device)\n",
    "        # print(self.replay_buffer[0][0])\n",
    "        # draft_probs = self.replay_buffer[:, 0]\n",
    "        # target_probs = self.replay_buffer[:, 1]\n",
    "        draft_probs = torch.stack([x[0][0] for x in self.replay_buffer], dim=0)\n",
    "        target_probs = torch.stack([x[1][0] for x in self.replay_buffer], dim=0)\n",
    "\n",
    "        self.draft_model.train()\n",
    "\n",
    "        # for param in self.draft_model.parameters():\n",
    "        #     print(param.requires_grad)\n",
    "\n",
    "\n",
    "        # criterion = torch.nn.CrossEntropyLoss()\n",
    "        # print(draft_probs.shape, target_probs.shape)\n",
    "        loss = self.soft_cross_entropy(draft_probs, target_probs)\n",
    "        print(\"Loss grad_fn:\", loss.grad_fn)\n",
    "        print(\"Draft probs grad_fn:\", draft_probs.grad_fn)\n",
    "        print(\"Target probs grad_fn:\", target_probs.grad_fn)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        self.draft_model.eval()\n",
    "\n",
    "        # Clear the replay buffer\n",
    "        self.replay_buffer = []\n",
    "\n",
    "    def soft_cross_entropy(self, predicts, targets, padding_mask=None):\n",
    "        predict_log_prob = torch.nn.functional.log_softmax(predicts, dim=-1)\n",
    "        targets_prob = torch.nn.functional.softmax(targets, dim=-1)\n",
    "        entropy = -targets_prob * predict_log_prob\n",
    "        # expand_mask = padding_mask.unsqueeze(-1).expand_as(entropy)\n",
    "        # entropy.masked_fill_(expand_mask, 0)\n",
    "        # mean_entropy = entropy.sum() / (~padding_mask).sum()\n",
    "        return entropy\n",
    "\n",
    "    def translate(\n",
    "        self,\n",
    "        source_text: str,\n",
    "        max_length: int = 128\n",
    "    ) -> str:\n",
    "        \"\"\"Translate source text using speculative decoding.\"\"\"\n",
    "        # Encode source text\n",
    "        encoder_inputs = self.tokenizer(\n",
    "            f\"translate English to German: {source_text}\",\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Initialize with start token\n",
    "        decoder_input_ids = torch.tensor([[self.tokenizer.pad_token_id]], device=self.device)\n",
    "\n",
    "        self.iteration_count = 0\n",
    "        self.replay_buffer = []\n",
    "\n",
    "        while decoder_input_ids.shape[1] < max_length:\n",
    "            self.temp_buffer = []\n",
    "\n",
    "            while decoder_input_ids.shape[1] < max_length:\n",
    "                # Get draft tokens autoregressively\n",
    "                # print(\"Encoder Inputs\", encoder_inputs.input_ids.shape)\n",
    "                draft_tokens, draft_probs, proposed_decoder_ids, draft_logits = self.get_draft_logits(\n",
    "                    encoder_inputs.input_ids,\n",
    "                    encoder_inputs.attention_mask,\n",
    "                    decoder_input_ids,\n",
    "                    self.gamma\n",
    "                )\n",
    "\n",
    "                draft_tokens = torch.tensor(draft_tokens, device=self.device)\n",
    "                draft_probs = torch.tensor(draft_probs, device=self.device)\n",
    "\n",
    "                if len(draft_tokens) == 0:\n",
    "                    break\n",
    "\n",
    "                # Get target probabilities in parallel\n",
    "                target_probs, target_logits = self.get_target_probs(\n",
    "                    encoder_inputs.input_ids,\n",
    "                    encoder_inputs.attention_mask,\n",
    "                    decoder_input_ids,\n",
    "                    draft_tokens\n",
    "                )\n",
    "                # print(draft_logits.shape, target_logits.shape)\n",
    "\n",
    "                # Verify tokens\n",
    "                n_accepted = self.verify_tokens(target_probs, draft_tokens, draft_probs)\n",
    "\n",
    "                # Accept verified tokens\n",
    "                if n_accepted > 0:\n",
    "                    decoder_input_ids = torch.cat([\n",
    "                        decoder_input_ids,\n",
    "                        draft_tokens[:n_accepted].unsqueeze(0)\n",
    "                    ], dim=1)\n",
    "\n",
    "                # # If rejection or no acceptance, sample one token from target\n",
    "                # if n_accepted < len(draft_tokens):\n",
    "                #     with torch.no_grad():\n",
    "                #         outputs = self.target_model(\n",
    "                #             input_ids=encoder_inputs.input_ids,\n",
    "                #             attention_mask=encoder_inputs.attention_mask,\n",
    "                #             decoder_input_ids=decoder_input_ids,\n",
    "                #             return_dict=True\n",
    "                #         )\n",
    "                #         logits = outputs.logits[:, -1, :]\n",
    "                #         probs = F.softmax(logits, dim=-1)\n",
    "                #         token_id = torch.multinomial(probs, num_samples=1)\n",
    "                #         decoder_input_ids = torch.cat([decoder_input_ids, token_id], dim=1)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # print(target_logits.shape, draft_logits.shape)\n",
    "                    probs = target_logits[:, -1, :] #- draft_logits[:, -1, :]\n",
    "                    probs = F.softmax(probs, dim=-1)\n",
    "                    token_id = torch.multinomial(probs, num_samples=1)\n",
    "                    # print(probs.shape, token_id.shape)\n",
    "                    decoder_input_ids = torch.cat([decoder_input_ids, token_id], dim=1)\n",
    "\n",
    "                # Check for end of sequence\n",
    "                if decoder_input_ids[0][-1].item() == self.tokenizer.eos_token_id:\n",
    "                    break\n",
    "                \n",
    "                # TODO: Update buffer with draft and target logits of the first rejected token, verify implementation\n",
    "                # rejected_tokens = draft_tokens[n_accepted]\n",
    "                if n_accepted < len(draft_tokens):\n",
    "                    # rejected_prob_draft = draft_logits[:, n_accepted, :]\n",
    "                    # rejected_prob_target = target_logits[:, n_accepted, :]\n",
    "\n",
    "                    self.temp_buffer.append((draft_logits[:, -1, :], target_logits[:, -1, :]))\n",
    "\n",
    "                # Check for end of sequence\n",
    "                if decoder_input_ids[0][-1].item() == self.tokenizer.eos_token_id:\n",
    "                    break\n",
    "\n",
    "            self.replay_buffer.extend(self.temp_buffer)\n",
    "            self.iteration_count += 1\n",
    "\n",
    "            if self.iteration_count % self.update_interval == 0:\n",
    "                self.update_draft_model()\n",
    "                self.iteration_count = 0\n",
    "\n",
    "        # Decode translation\n",
    "        translation = self.tokenizer.decode(\n",
    "            decoder_input_ids[0],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize decoder\n",
    "online_decoder = OnlineSpeculativeDecoder()\n",
    "\n",
    "# Example translation\n",
    "source_text = \"In a world where technology evolves at an unprecedented pace, individuals and organizations must adapt quickly to the rapid advancements in artificial intelligence, machine learning, and automation, ensuring that ethical considerations, environmental sustainability, and equitable access to resources are prioritized to create a future that benefits all of humanity.\"\n",
    "\n",
    "# Time the translation\n",
    "start_time = time.time()\n",
    "translation = online_decoder.translate(source_text)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Source: {source_text}\")\n",
    "print(f\"Translation: {translation}\\n\")\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineSpeculativeDecoder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_model_name = \"google-t5/t5-large\",\n",
    "        draft_model_name = \"google-t5/t5-small\",\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        gamma = 4,\n",
    "        update_interval=2,  # Update draft model after every `update_interval` iterations\n",
    "        buffer_size_threshold=2,  # Buffer size threshold for updates\n",
    "        time_threshold=2,  # Time threshold (in seconds) for updates\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.gamma = gamma\n",
    "        self.update_interval = update_interval\n",
    "        self.buffer_size_threshold = buffer_size_threshold\n",
    "        self.time_threshold = time_threshold\n",
    "        self.last_update_time = time.time()  # Track last update time\n",
    "\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(target_model_name)\n",
    "        self.target_model = T5ForConditionalGeneration.from_pretrained(target_model_name).to(device)\n",
    "        self.draft_model = T5ForConditionalGeneration.from_pretrained(draft_model_name).to(device)\n",
    "\n",
    "        self.target_model.eval()\n",
    "        self.draft_model.eval()\n",
    "\n",
    "        # Buffers for storing token proposals and updates\n",
    "        self.replay_buffer = []\n",
    "        self.temp_buffer = []  # Temporary buffer for a single request\n",
    "\n",
    "        # Counter for iteration tracking\n",
    "        self.iteration_count = 0\n",
    "\n",
    "    def get_draft_logits(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        decoder_input_ids: torch.Tensor,\n",
    "        gamma: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Get draft logits for gamma tokens\"\"\"\n",
    "        draft_tokens = []\n",
    "        draft_probs = []\n",
    "        current_decoder_ids = decoder_input_ids\n",
    "\n",
    "        # Generate gamma tokens from the draft model\n",
    "        for _ in range(gamma):\n",
    "            with torch.no_grad():\n",
    "                outputs = self.draft_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    decoder_input_ids=current_decoder_ids,\n",
    "                    return_dict=True\n",
    "                )\n",
    "                logits = outputs.logits[:, -1, :]  # Get logits for last position\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                # Sample token\n",
    "                token_id = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "                prob = probs.gather(-1, token_id.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "                draft_tokens.append(token_id.item())\n",
    "                draft_probs.append(prob.item())\n",
    "\n",
    "                # Update decoder inputs for next iteration\n",
    "                current_decoder_ids = torch.cat(\n",
    "                    [current_decoder_ids, token_id.view(1, 1)],\n",
    "                    dim=1\n",
    "                )\n",
    "\n",
    "                if token_id.item() == self.tokenizer.eos_token_id:\n",
    "                    break\n",
    "\n",
    "        return draft_tokens, draft_probs, current_decoder_ids, outputs.logits\n",
    "\n",
    "    def get_target_probs(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        decoder_input_ids: torch.Tensor,\n",
    "        draft_tokens: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Get target probabilities for the draft tokens in parallel.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Add draft tokens to decoder input\n",
    "            full_decoder_ids = torch.cat([decoder_input_ids, draft_tokens.unsqueeze(0)], dim=1)\n",
    "\n",
    "            outputs = self.target_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                decoder_input_ids=full_decoder_ids,\n",
    "                return_dict=True\n",
    "            )\n",
    "\n",
    "            # Get probabilities for positions before each draft token\n",
    "            logits = outputs.logits[:, -(len(draft_tokens) + 1):-1, :]\n",
    "            target_probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            return target_probs.squeeze(0), outputs.logits\n",
    "        \n",
    "    def get_logits(self, model, input_ids, attention_mask, decoder_input_ids):\n",
    "        return model(\n",
    "            input_ids=input_ids,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        ).logits\n",
    "\n",
    "    def verify_tokens(\n",
    "        self,\n",
    "        target_probs: torch.Tensor,\n",
    "        draft_tokens: torch.Tensor,\n",
    "        draft_probs: torch.Tensor,\n",
    "    ) -> int:\n",
    "        \"\"\"Determine number of accepted tokens\"\"\"\n",
    "        # Get target probabilities for the draft tokens\n",
    "        target_probs_draft_tokens = target_probs.gather(\n",
    "            -1,\n",
    "            draft_tokens.unsqueeze(-1)\n",
    "        ).squeeze(-1)\n",
    "\n",
    "        # Calculate acceptance ratios\n",
    "        acceptance_ratios = target_probs_draft_tokens / draft_probs\n",
    "\n",
    "        # Sample uniform random numbers\n",
    "        random_nums = torch.rand_like(acceptance_ratios)\n",
    "\n",
    "        # Find number of accepted tokens\n",
    "        # Accept if random number < min(1, target_prob / draft_prob)\n",
    "        accepts = random_nums < torch.minimum(\n",
    "            torch.ones_like(acceptance_ratios),\n",
    "            acceptance_ratios\n",
    "        )\n",
    "\n",
    "        # Find first rejection\n",
    "        try:\n",
    "            n_accepted = torch.where(~accepts)[0][0].item()\n",
    "        except:\n",
    "            n_accepted = len(accepts)\n",
    "\n",
    "        return n_accepted\n",
    "\n",
    "        # accepted_tokens = []\n",
    "        # for i in range(len(draft_tokens)):\n",
    "        #     if target_probs[i] / draft_probs[i] > torch.rand(1).item():\n",
    "        #         accepted_tokens.append(draft_tokens[i])\n",
    "        #     else:\n",
    "        #         break # Stop if token is not accepted\n",
    "\n",
    "        # return len(accepted_tokens)\n",
    "    \n",
    "    # TODO: verify this, might need to do some window size thing\n",
    "    # def update_draft_model(self):\n",
    "    #     \"\"\"Update draft model with the replay buffer.\"\"\"\n",
    "    #     if len(self.replay_buffer) == 0:\n",
    "    #         return\n",
    "\n",
    "    #     # Get draft tokens, draft and target probabilities from the replay buffer\n",
    "    #     draft_tokens = torch.tensor([x[0] for x in self.replay_buffer], device=self.device)\n",
    "    #     target_logits = torch.tensor([x[1] for x in self.replay_buffer], device=self.device)\n",
    "\n",
    "    #     encoder_inputs = s\n",
    "    #     output = self.draft_model(\n",
    "    #         input_ids=encoder_inputs.input_ids,\n",
    "    #         attention_mask=encoder_inputs.attention_mask,\n",
    "    #         decoder_input_ids=decoder_input_ids,\n",
    "    #         return_dict=True\n",
    "    #     )\n",
    "\n",
    "    def pad_to_2d(self, tensor_list, pad_token_id, max_len=None):\n",
    "        if not isinstance(tensor_list[0], torch.Tensor):\n",
    "            tensor_list = [torch.tensor(t).reshape(1, -1) for t in tensor_list]\n",
    "        if max_len is None:\n",
    "            max_len = max([t.shape[-1] for t in tensor_list])\n",
    "        assert max_len > 0\n",
    "\n",
    "        # Pad each tensor to the max length and stack them to form a 2D tensor\n",
    "        result = torch.cat(\n",
    "            [\n",
    "                torch.nn.functional.pad(\n",
    "                    tensor, (0, max_len - tensor.shape[-1]),\n",
    "                    value=pad_token_id\n",
    "                )\n",
    "                for tensor in tensor_list\n",
    "            ],\n",
    "            dim=0\n",
    "        )\n",
    "        return result\n",
    "        \n",
    "\n",
    "    def soft_cross_entropy(self, predicts, targets, padding_mask=None):\n",
    "        predict_log_prob = torch.nn.functional.log_softmax(predicts, dim=-1)\n",
    "        targets_prob = torch.nn.functional.softmax(targets, dim=-1)\n",
    "        entropy = -targets_prob * predict_log_prob\n",
    "        expand_mask = padding_mask.unsqueeze(-1).expand_as(entropy)\n",
    "        entropy.masked_fill_(expand_mask, 0)\n",
    "        mean_entropy = entropy.sum() / (~padding_mask).sum()\n",
    "        return mean_entropy\n",
    "\n",
    "    def translate_dataset(\n",
    "        self,\n",
    "        sentences: List[str],\n",
    "        max_length: int = 128\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Translate dataset using online speculative decoding.\"\"\"\n",
    "\n",
    "        self.iteration_count = 0\n",
    "        self.replay_buffer = []\n",
    "\n",
    "        translated_data = []\n",
    "\n",
    "        for source_text in sentences:\n",
    "            # Encode source text\n",
    "            encoder_inputs = self.tokenizer(\n",
    "                f\"translate English to German: {source_text}\",\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True\n",
    "            ).to(self.device)\n",
    "\n",
    "            # Initialize with start token\n",
    "            decoder_input_ids = torch.tensor([[self.tokenizer.pad_token_id]], device=self.device)\n",
    "            self.temp_buffer = []\n",
    "\n",
    "            while decoder_input_ids.shape[1] < max_length:\n",
    "\n",
    "                # Check for end of sequence\n",
    "                if decoder_input_ids[0][-1].item() == self.tokenizer.eos_token_id:\n",
    "                    break\n",
    "\n",
    "                # Get draft tokens autoregressively\n",
    "                # print(\"Encoder Inputs\", encoder_inputs.input_ids.shape)\n",
    "                draft_tokens, draft_probs, proposed_decoder_ids, draft_logits = self.get_draft_logits(\n",
    "                    encoder_inputs.input_ids,\n",
    "                    encoder_inputs.attention_mask,\n",
    "                    decoder_input_ids,\n",
    "                    self.gamma\n",
    "                )\n",
    "\n",
    "                draft_tokens = torch.tensor(draft_tokens, device=self.device)\n",
    "                draft_probs = torch.tensor(draft_probs, device=self.device)\n",
    "\n",
    "                if len(draft_tokens) == 0:\n",
    "                    break\n",
    "\n",
    "                # Get target probabilities in parallel\n",
    "                target_probs, target_logits = self.get_target_probs(\n",
    "                    encoder_inputs.input_ids,\n",
    "                    encoder_inputs.attention_mask,\n",
    "                    decoder_input_ids,\n",
    "                    draft_tokens\n",
    "                )\n",
    "                # print(draft_logits.shape, target_logits.shape)\n",
    "\n",
    "                # Verify tokens\n",
    "                n_accepted = self.verify_tokens(target_probs, draft_tokens, draft_probs)\n",
    "\n",
    "                # Accept verified tokens\n",
    "                if n_accepted > 0:\n",
    "                    decoder_input_ids = torch.cat([\n",
    "                        decoder_input_ids,\n",
    "                        draft_tokens[:n_accepted].unsqueeze(0)\n",
    "                    ], dim=1)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # print(target_logits.shape, draft_logits.shape)\n",
    "                    probs = target_logits[:, -1, :] #- draft_logits[:, -1, :]\n",
    "                    probs = F.softmax(probs, dim=-1)\n",
    "                    token_id = torch.multinomial(probs, num_samples=1)\n",
    "                    # print(probs.shape, token_id.shape)\n",
    "                    decoder_input_ids = torch.cat([decoder_input_ids, token_id], dim=1)\n",
    "                \n",
    "                # rejected_tokens = draft_tokens[n_accepted]\n",
    "                if n_accepted < len(draft_tokens):\n",
    "\n",
    "                    self.temp_buffer.append((encoder_inputs, decoder_input_ids, target_logits, n_accepted))\n",
    "\n",
    "            self.replay_buffer.extend(self.temp_buffer)\n",
    "            self.iteration_count += 1\n",
    "\n",
    "            if self.iteration_count % self.update_interval == 0:\n",
    "                # self.update_draft_model()\n",
    "                self.draft_model.train()\n",
    "                \n",
    "                # finetune over collected tokens and logits\n",
    "                encoder_input_ids = self.pad_to_2d([x[0].input_ids for x in self.replay_buffer], 0)\n",
    "                encoder_attention_mask = torch.stack([x[0].attention_mask[0] for x in self.replay_buffer], dim=0)\n",
    "                decoder_input_ids = self.pad_to_2d([x[1] for x in self.replay_buffer], 0, 512)\n",
    "\n",
    "                print(encoder_input_ids.shape, encoder_attention_mask.shape, decoder_input_ids.shape)\n",
    "\n",
    "                target_logits = [x[2] for x in self.replay_buffer]\n",
    "                for i in range(len(target_logits)):\n",
    "                    temp = torch.zeros(1, 32128, device=self.device).repeat(512 - target_logits[i].shape[1], 1).unsqueeze(0)\n",
    "                    target_logits[i] = torch.cat([target_logits[i], temp], dim=1)\n",
    "\n",
    "                n_accepted_tokens = [x[3] for x in self.replay_buffer]\n",
    "\n",
    "                # CUDA out of memory error\n",
    "                draft_logits = self.get_logits(self.draft_model, encoder_input_ids, encoder_attention_mask, decoder_input_ids).float()\n",
    "\n",
    "                # need to get loss only using the wrong tokens\n",
    "                # TODO: check if we need to ignore the pad tokens in the mask\n",
    "                mask = torch.ones_like(decoder_input_ids, dtype=torch.bool)\n",
    "                for i in range(len(n_accepted_tokens)):\n",
    "                    mask[i, n_accepted_tokens[i]:] = False\n",
    "                loss = self.soft_cross_entropy(draft_logits, target_logits, mask)\n",
    "                loss.backward()\n",
    "\n",
    "                self.draft_model.eval()\n",
    "                self.replay_buffer = []\n",
    "                self.iteration_count = 0\n",
    "\n",
    "            # Decode translation\n",
    "            translation = self.tokenizer.decode(\n",
    "                decoder_input_ids[0],\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            translated_data.append(translation)\n",
    "        return translated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecbc2d7857e470e9ea6e29d26a4858c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c2b031c23f4e6687d6e1848f0835f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a77ea7ac314c5d9df6f33c31b03c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bd4b98482e4a5299176eab4388119b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a56b1e3c42c49c5a0315bb1af19dada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 69]) torch.Size([28, 69]) torch.Size([28, 512])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 40.50 MiB is free. Including non-PyTorch memory, this process has 10.71 GiB memory in use. Of the allocated memory 9.81 GiB is allocated by PyTorch, and 111.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Time the translation\u001b[39;00m\n\u001b[1;32m      8\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m translation \u001b[39m=\u001b[39m online_decoder\u001b[39m.\u001b[39;49mtranslate_dataset(sents)\n\u001b[1;32m     10\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i, sent \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sents):\n",
      "Cell \u001b[0;32mIn[7], line 291\u001b[0m, in \u001b[0;36mOnlineSpeculativeDecoder.translate_dataset\u001b[0;34m(self, sentences, max_length)\u001b[0m\n\u001b[1;32m    289\u001b[0m target_logits \u001b[39m=\u001b[39m [x[\u001b[39m2\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer]\n\u001b[1;32m    290\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(target_logits)):\n\u001b[0;32m--> 291\u001b[0m     temp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m, \u001b[39m32128\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\u001b[39m.\u001b[39;49mrepeat(\u001b[39m512\u001b[39;49m \u001b[39m-\u001b[39;49m target_logits[i]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    292\u001b[0m     target_logits[i] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([target_logits[i], temp], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    294\u001b[0m n_accepted_tokens \u001b[39m=\u001b[39m [x[\u001b[39m3\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 40.50 MiB is free. Including non-PyTorch memory, this process has 10.71 GiB memory in use. Of the allocated memory 9.81 GiB is allocated by PyTorch, and 111.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Initialize decoder\n",
    "online_decoder = OnlineSpeculativeDecoder()\n",
    "\n",
    "# Example translation\n",
    "source_text = \"In a world where technology evolves at an unprecedented pace, individuals and organizations must adapt quickly to the rapid advancements in artificial intelligence, machine learning, and automation, ensuring that ethical considerations, environmental sustainability, and equitable access to resources are prioritized to create a future that benefits all of humanity.\"\n",
    "sents = [source_text] * 10\n",
    "# Time the translation\n",
    "start_time = time.time()\n",
    "translation = online_decoder.translate_dataset(sents)\n",
    "end_time = time.time()\n",
    "\n",
    "for i, sent in enumerate(sents):\n",
    "    print(f\"Source: {sent}\")\n",
    "    print(f\"Translation: {translation[i]}\\n\")\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
